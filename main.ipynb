{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and cleaning data...\n",
      "Data shape: (54681, 11)\n",
      "Missing values:\n",
      "id                          0\n",
      "city_name                   0\n",
      "signup_os                6857\n",
      "signup_channel              0\n",
      "signup_date                 0\n",
      "bgc_date                21785\n",
      "vehicle_added_date      41547\n",
      "vehicle_make            41458\n",
      "vehicle_model           41458\n",
      "vehicle_year            41458\n",
      "first_completed_date    48544\n",
      "dtype: int64\n",
      "\n",
      "Performing exploratory data analysis...\n",
      "\n",
      "Overall Conversion Stats:\n",
      "Total Drivers: 54681\n",
      "Drivers who took first trip: 6137\n",
      "Conversion Rate: 11.22%\n",
      "\n",
      "Conversion by Background Check Status:\n",
      "BGC Completed: 18.66% (6137/32896)\n",
      "No BGC: 0.00% (0/21785)\n",
      "\n",
      "Conversion by Vehicle Addition Status:\n",
      "Vehicle Added: 44.71% (5872/13134)\n",
      "No Vehicle: 0.64% (265/41547)\n",
      "\n",
      "Conversion by Signup Channel:\n",
      "Organic: 9.01% (1210/13427)\n",
      "Paid: 6.19% (1482/23938)\n",
      "Referral: 19.89% (3445/17316)\n",
      "\n",
      "Conversion by Funnel Completion:\n",
      "BGC Only: 1.32% (265/20017)\n",
      "BGC and Vehicle: 45.59% (5872/12879)\n",
      "No BGC, No Vehicle: 0.00% (0/21530)\n",
      "Vehicle Only: 0.00% (0/255)\n",
      "\n",
      "Creating visualizations...\n",
      "\n",
      "Building predictive model...\n",
      "\n",
      "Model Performance:\n",
      "Accuracy: 0.8933\n",
      "Precision: 0.5258\n",
      "Recall: 0.5450\n",
      "F1 Score: 0.5352\n",
      "\n",
      "Confusion Matrix:\n",
      "[[9098  606]\n",
      " [ 561  672]]\n",
      "\n",
      "Feature Importance:\n",
      "                   Feature  Importance\n",
      "6            bgc_completed    4.493994\n",
      "8         has_vehicle_info    2.191576\n",
      "7            vehicle_added    1.847814\n",
      "2  signup_channel_Referral    0.305712\n",
      "1      signup_channel_Paid    0.210220\n",
      "0   signup_channel_Organic    0.095577\n",
      "3         city_name_Berton    0.065396\n",
      "4         city_name_Strark    0.054656\n",
      "5        city_name_Wrouver    0.010825\n",
      "\n",
      "Visualizing model performance...\n",
      "\n",
      "Analysis complete. Visualizations saved to files.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set styling for plots\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"viridis\")\n",
    "\n",
    "# Define a function to load and clean the data\n",
    "def load_and_clean_data(file_path):\n",
    "    \"\"\"\n",
    "    Load and clean the Uber driver signup data.\n",
    "    \n",
    "    Parameters:\n",
    "    file_path (str): Path to the CSV file\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Cleaned dataframe\n",
    "    \"\"\"\n",
    "    # Read the data\n",
    "    df = pd.read_csv(file_path, na_values=\"NA\")\n",
    "    \n",
    "    # Check basic info\n",
    "    print(f\"Data shape: {df.shape}\")\n",
    "    print(f\"Missing values:\\n{df.isnull().sum()}\")\n",
    "    \n",
    "    # Convert date columns to datetime\n",
    "    date_columns = ['signup_date', 'bgc_date', 'vehicle_added_date', 'first_completed_date']\n",
    "    for col in date_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "    \n",
    "    # Create target variable: did the driver take their first trip?\n",
    "    df['started_driving'] = (~df['first_completed_date'].isna()).astype(int)\n",
    "    \n",
    "    # Create binary features for key steps\n",
    "    df['bgc_completed'] = (~df['bgc_date'].isna()).astype(int)\n",
    "    df['vehicle_added'] = (~df['vehicle_added_date'].isna()).astype(int)\n",
    "    df['has_vehicle_info'] = (~df['vehicle_make'].isna()).astype(int)\n",
    "    \n",
    "    # Calculate days between signup and other events\n",
    "    df['days_to_bgc'] = (df['bgc_date'] - df['signup_date']).dt.days\n",
    "    df['days_to_vehicle'] = (df['vehicle_added_date'] - df['signup_date']).dt.days\n",
    "    df['days_to_first_trip'] = (df['first_completed_date'] - df['signup_date']).dt.days\n",
    "    \n",
    "    # Create vehicle age feature\n",
    "    current_year = pd.to_datetime('now').year\n",
    "    df['vehicle_age'] = current_year - df['vehicle_year']\n",
    "    \n",
    "    # Create funnel completion status\n",
    "    conditions = [\n",
    "        (df['bgc_completed'] == 0) & (df['vehicle_added'] == 0),\n",
    "        (df['bgc_completed'] == 1) & (df['vehicle_added'] == 0),\n",
    "        (df['bgc_completed'] == 0) & (df['vehicle_added'] == 1),\n",
    "        (df['bgc_completed'] == 1) & (df['vehicle_added'] == 1)\n",
    "    ]\n",
    "    choices = ['No BGC, No Vehicle', 'BGC Only', 'Vehicle Only', 'BGC and Vehicle']\n",
    "    df['funnel_status'] = np.select(conditions, choices, default=None)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Define function for exploratory data analysis\n",
    "def perform_eda(df):\n",
    "    \"\"\"\n",
    "    Perform exploratory data analysis on the driver signup data.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Cleaned dataframe\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Overall conversion rate\n",
    "    total_drivers = len(df)\n",
    "    converted_drivers = df['started_driving'].sum()\n",
    "    conversion_rate = converted_drivers / total_drivers * 100\n",
    "    \n",
    "    print(f\"\\nOverall Conversion Stats:\")\n",
    "    print(f\"Total Drivers: {total_drivers}\")\n",
    "    print(f\"Drivers who took first trip: {converted_drivers}\")\n",
    "    print(f\"Conversion Rate: {conversion_rate:.2f}%\")\n",
    "    \n",
    "    # Conversion by background check status\n",
    "    bgc_stats = df.groupby('bgc_completed')['started_driving'].agg(['count', 'sum'])\n",
    "    bgc_stats['conversion_rate'] = bgc_stats['sum'] / bgc_stats['count'] * 100\n",
    "    \n",
    "    print(\"\\nConversion by Background Check Status:\")\n",
    "    print(f\"BGC Completed: {bgc_stats.loc[1, 'conversion_rate']:.2f}% ({bgc_stats.loc[1, 'sum']}/{bgc_stats.loc[1, 'count']})\")\n",
    "    print(f\"No BGC: {bgc_stats.loc[0, 'conversion_rate']:.2f}% ({bgc_stats.loc[0, 'sum']}/{bgc_stats.loc[0, 'count']})\")\n",
    "    \n",
    "    # Conversion by vehicle addition status\n",
    "    vehicle_stats = df.groupby('vehicle_added')['started_driving'].agg(['count', 'sum'])\n",
    "    vehicle_stats['conversion_rate'] = vehicle_stats['sum'] / vehicle_stats['count'] * 100\n",
    "    \n",
    "    print(\"\\nConversion by Vehicle Addition Status:\")\n",
    "    print(f\"Vehicle Added: {vehicle_stats.loc[1, 'conversion_rate']:.2f}% ({vehicle_stats.loc[1, 'sum']}/{vehicle_stats.loc[1, 'count']})\")\n",
    "    print(f\"No Vehicle: {vehicle_stats.loc[0, 'conversion_rate']:.2f}% ({vehicle_stats.loc[0, 'sum']}/{vehicle_stats.loc[0, 'count']})\")\n",
    "    \n",
    "    # Conversion by signup channel\n",
    "    channel_stats = df.groupby('signup_channel')['started_driving'].agg(['count', 'sum'])\n",
    "    channel_stats['conversion_rate'] = channel_stats['sum'] / channel_stats['count'] * 100\n",
    "    \n",
    "    print(\"\\nConversion by Signup Channel:\")\n",
    "    for channel in channel_stats.index:\n",
    "        print(f\"{channel}: {channel_stats.loc[channel, 'conversion_rate']:.2f}% ({channel_stats.loc[channel, 'sum']}/{channel_stats.loc[channel, 'count']})\")\n",
    "    \n",
    "    # Conversion by funnel completion\n",
    "    funnel_stats = df.groupby('funnel_status')['started_driving'].agg(['count', 'sum'])\n",
    "    funnel_stats['conversion_rate'] = funnel_stats['sum'] / funnel_stats['count'] * 100\n",
    "    \n",
    "    print(\"\\nConversion by Funnel Completion:\")\n",
    "    for status in funnel_stats.index:\n",
    "        print(f\"{status}: {funnel_stats.loc[status, 'conversion_rate']:.2f}% ({funnel_stats.loc[status, 'sum']}/{funnel_stats.loc[status, 'count']})\")\n",
    "    \n",
    "    return {\n",
    "        'bgc_stats': bgc_stats,\n",
    "        'vehicle_stats': vehicle_stats,\n",
    "        'channel_stats': channel_stats,\n",
    "        'funnel_stats': funnel_stats\n",
    "    }\n",
    "\n",
    "# Define function to create visualizations\n",
    "def create_visualizations(df, stats):\n",
    "    \"\"\"\n",
    "    Create visualizations for the driver signup data.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Cleaned dataframe\n",
    "    stats (dict): Statistics from EDA\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Create a figure for multiple plots\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    \n",
    "    # Plot 1: Conversion by Funnel Status\n",
    "    plt.subplot(2, 2, 1)\n",
    "    funnel_df = stats['funnel_stats'].reset_index()\n",
    "    sns.barplot(x='funnel_status', y='conversion_rate', data=funnel_df)\n",
    "    plt.title('Conversion Rate by Funnel Completion')\n",
    "    plt.xlabel('Funnel Status')\n",
    "    plt.ylabel('Conversion Rate (%)')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # Plot 2: Conversion by Signup Channel\n",
    "    plt.subplot(2, 2, 2)\n",
    "    channel_df = stats['channel_stats'].reset_index()\n",
    "    sns.barplot(x='signup_channel', y='conversion_rate', data=channel_df)\n",
    "    plt.title('Conversion Rate by Signup Channel')\n",
    "    plt.xlabel('Signup Channel')\n",
    "    plt.ylabel('Conversion Rate (%)')\n",
    "    \n",
    "    # Plot 3: Time to Complete Steps vs Conversion\n",
    "    plt.subplot(2, 2, 3)\n",
    "    \n",
    "    # Create bins for days to BGC\n",
    "    df_bgc = df[df['bgc_completed'] == 1].copy()\n",
    "    df_bgc['days_to_bgc_bin'] = pd.cut(\n",
    "        df_bgc['days_to_bgc'],\n",
    "        bins=[-1, 0, 3, 7, 14, float('inf')],\n",
    "        labels=['Same day', '1-3 days', '4-7 days', '8-14 days', '15+ days']\n",
    "    )\n",
    "    \n",
    "    bgc_time_stats = df_bgc.groupby('days_to_bgc_bin')['started_driving'].agg(['count', 'mean'])\n",
    "    bgc_time_stats['conversion_rate'] = bgc_time_stats['mean'] * 100\n",
    "    \n",
    "    sns.barplot(x=bgc_time_stats.index, y='conversion_rate', data=bgc_time_stats)\n",
    "    plt.title('Conversion Rate by Time to Complete Background Check')\n",
    "    plt.xlabel('Days to Complete BGC')\n",
    "    plt.ylabel('Conversion Rate (%)')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # Plot 4: Distribution of Converted vs Non-converted Drivers\n",
    "    plt.subplot(2, 2, 4)\n",
    "    conversion_counts = df['started_driving'].value_counts()\n",
    "    plt.pie(conversion_counts, labels=['Did not start driving', 'Started driving'], \n",
    "            autopct='%1.1f%%', startangle=90, colors=['#ff9999','#66b3ff'])\n",
    "    plt.title('Distribution of Driver Conversion')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('uber_driver_conversion_analysis.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Create a second figure for vehicle and BGC impact\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Plot 1: Impact of BGC completion\n",
    "    plt.subplot(1, 2, 1)\n",
    "    bgc_df = stats['bgc_stats'].reset_index()\n",
    "    bgc_df['status'] = bgc_df['bgc_completed'].map({0: 'No BGC', 1: 'BGC Completed'})\n",
    "    sns.barplot(x='status', y='conversion_rate', data=bgc_df)\n",
    "    plt.title('Impact of Background Check on Conversion')\n",
    "    plt.xlabel('Background Check Status')\n",
    "    plt.ylabel('Conversion Rate (%)')\n",
    "    \n",
    "    # Plot 2: Impact of vehicle addition\n",
    "    plt.subplot(1, 2, 2)\n",
    "    vehicle_df = stats['vehicle_stats'].reset_index()\n",
    "    vehicle_df['status'] = vehicle_df['vehicle_added'].map({0: 'No Vehicle', 1: 'Vehicle Added'})\n",
    "    sns.barplot(x='status', y='conversion_rate', data=vehicle_df)\n",
    "    plt.title('Impact of Vehicle Addition on Conversion')\n",
    "    plt.xlabel('Vehicle Status')\n",
    "    plt.ylabel('Conversion Rate (%)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('uber_driver_key_factors.png')\n",
    "    plt.close()\n",
    "\n",
    "# Define function to build and evaluate a predictive model\n",
    "def build_predictive_model(df):\n",
    "    \"\"\"\n",
    "    Build and evaluate a logistic regression model to predict driver conversion.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Cleaned dataframe\n",
    "    \n",
    "    Returns:\n",
    "    model: Trained model\n",
    "    X_test: Test features\n",
    "    y_test: Test targets\n",
    "    \"\"\"\n",
    "    # Select features and target\n",
    "    features = ['bgc_completed', 'vehicle_added', 'has_vehicle_info', 'signup_channel', 'city_name']\n",
    "    target = 'started_driving'\n",
    "    \n",
    "    # Select only the rows with non-null values for essential features\n",
    "    model_df = df[features + [target]].dropna()\n",
    "    \n",
    "    # Split the data\n",
    "    X = model_df[features]\n",
    "    y = model_df[target]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Create preprocessing pipeline\n",
    "    categorical_features = ['signup_channel', 'city_name']\n",
    "    categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "    \n",
    "    # Create model pipeline\n",
    "    model = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', LogisticRegression(max_iter=1000, random_state=42))\n",
    "    ])\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print(\"\\nModel Performance:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    \n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(cm)\n",
    "    \n",
    "    # Get feature importances\n",
    "    feature_names = (model.named_steps['preprocessor']\n",
    "                    .transformers_[0][1]\n",
    "                    .get_feature_names_out(categorical_features))\n",
    "    feature_names = np.append(feature_names, ['bgc_completed', 'vehicle_added', 'has_vehicle_info'])\n",
    "    \n",
    "    # Extract coefficients\n",
    "    coefficients = model.named_steps['classifier'].coef_[0]\n",
    "    \n",
    "    # Create DataFrame of feature importances\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': np.abs(coefficients)\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nFeature Importance:\")\n",
    "    print(feature_importance)\n",
    "    \n",
    "    return model, X_test, y_test, feature_importance\n",
    "\n",
    "# Function to visualize model performance\n",
    "def visualize_model_performance(model, X_test, y_test, feature_importance):\n",
    "    \"\"\"\n",
    "    Visualize model performance and feature importance.\n",
    "    \n",
    "    Parameters:\n",
    "    model: Trained model\n",
    "    X_test: Test features\n",
    "    y_test: Test targets\n",
    "    feature_importance: DataFrame of feature importances\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Create a figure for multiple plots\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    \n",
    "    # Plot 1: Confusion Matrix\n",
    "    plt.subplot(2, 1, 1)\n",
    "    y_pred = model.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    \n",
    "    # Plot 2: Feature Importance\n",
    "    plt.subplot(2, 1, 2)\n",
    "    top_features = feature_importance.head(10)\n",
    "    sns.barplot(x='Importance', y='Feature', data=top_features)\n",
    "    plt.title('Top 10 Feature Importances')\n",
    "    plt.xlabel('Absolute Coefficient Value')\n",
    "    plt.ylabel('Feature')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('uber_driver_model_performance.png')\n",
    "    plt.close()\n",
    "\n",
    "# Main function to run the entire analysis\n",
    "def main(file_path):\n",
    "    \"\"\"\n",
    "    Run the entire analysis pipeline.\n",
    "    \n",
    "    Parameters:\n",
    "    file_path (str): Path to the CSV file\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    print(\"Loading and cleaning data...\")\n",
    "    df = load_and_clean_data(file_path)\n",
    "    \n",
    "    print(\"\\nPerforming exploratory data analysis...\")\n",
    "    stats = perform_eda(df)\n",
    "    \n",
    "    print(\"\\nCreating visualizations...\")\n",
    "    create_visualizations(df, stats)\n",
    "    \n",
    "    print(\"\\nBuilding predictive model...\")\n",
    "    model, X_test, y_test, feature_importance = build_predictive_model(df)\n",
    "    \n",
    "    print(\"\\nVisualizing model performance...\")\n",
    "    visualize_model_performance(model, X_test, y_test, feature_importance)\n",
    "    \n",
    "    print(\"\\nAnalysis complete. Visualizations saved to files.\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    main('data1.csv')  # Replace with your file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================= UBER DRIVER CONVERSION RECOMMENDATIONS =================\n",
      "\n",
      "EXECUTIVE SUMMARY:\n",
      "Analysis of 54,681 driver signups reveals an overall conversion rate of 11.22%\n",
      "This means that 6,137 drivers completed their first trip, while 48,544 did not.\n",
      "Based on our analysis, we've identified key factors affecting conversion and developed recommendations.\n",
      "\n",
      "KEY FINDINGS:\n",
      "1. Background Check Completion: Drivers who complete their background check are 18.7x more likely to take their first trip.\n",
      "2. Vehicle Addition: Drivers who add a vehicle are 46.7x more likely to take their first trip.\n",
      "3. Signup Channel: Drivers from referrals convert at 35.44%, which is infx better than paid channels.\n",
      "4. Full Funnel Completion: Drivers who complete both BGC and add a vehicle convert at 46.73%.\n",
      "\n",
      "RECOMMENDATIONS:\n",
      "1. Prioritize Vehicle Addition Process\n",
      "   - The data shows vehicle addition is the strongest predictor of first trips\n",
      "   - Implement a simplified vehicle registration flow with fewer steps\n",
      "   - Create guided tutorials for vehicle upload to reduce friction\n",
      "   - Send targeted reminders to drivers who haven't added vehicle information\n",
      "   - Targeting the 19,762 drivers who completed BGC but haven't added a vehicle would yield highest ROI\n",
      "\n",
      "2. Streamline Background Check Process\n",
      "   - Optimize the background check submission workflow to reduce drop-offs\n",
      "   - Improve communication about the BGC timeline and expectations\n",
      "   - Implement a progress tracker to encourage completion\n",
      "   - Send automated reminders with direct links to resume the process\n",
      "\n",
      "3. Expand the Referral Program\n",
      "   - Referrals convert at 35.44%, significantly higher than other channels\n",
      "   - Consider increasing referral bonuses to generate more referral signups\n",
      "   - Create a buddy system to pair new drivers with experienced drivers\n",
      "   - Develop team incentives for referring drivers to help others complete their first trip\n",
      "\n",
      "4. Implement Targeted Interventions\n",
      "   - Use the predictive model to identify drivers most likely to convert\n",
      "   - Create a tiered re-engagement strategy for stalled applications\n",
      "   - Pilot a high-touch concierge service for high-potential drivers\n",
      "   - Develop custom messaging based on where drivers get stuck in the funnel\n",
      "\n",
      "5. Improve Paid Channel Quality\n",
      "   - Paid channels have the lowest conversion at 0.00%\n",
      "   - Revisit targeting criteria to attract more qualified potential drivers\n",
      "   - Test different messaging that sets clearer expectations about the process\n",
      "   - Consider requiring more pre-qualification in paid campaigns\n",
      "\n",
      "IMPLEMENTATION ROADMAP:\n",
      "Phase 1: Quick Wins (Next 30 Days)\n",
      "  • Email/SMS campaign for drivers who completed background checks but haven't added vehicles\n",
      "  • Simplify the vehicle information form to require only essential information\n",
      "  • Implement progress visualization in the driver app\n",
      "\n",
      "Phase 2: Medium-Term Solutions (60-90 Days)\n",
      "  • Develop a predictive intervention system using the model\n",
      "  • Redesign the vehicle addition flow with a guided experience\n",
      "  • Expand the referral program with new incentives\n",
      "  • Create a concierge service pilot for high-potential drivers\n",
      "\n",
      "Phase 3: Longer-Term Initiatives (90+ Days)\n",
      "  • Build an integrated onboarding experience with personalized guidance\n",
      "  • Develop partnerships to help drivers overcome vehicle barriers\n",
      "  • Implement A/B testing program for continuous funnel optimization\n",
      "  • Create a driver community platform to facilitate peer support\n",
      "\n",
      "EXPECTED IMPACT:\n",
      "Current Driver Conversion: 11.22% (6,137 of 54,681 drivers)\n",
      "Conservative Scenario: 12.91% conversion (+920 drivers)\n",
      "Moderate Scenario: 14.59% conversion (+1,841 drivers)\n",
      "Aggressive Scenario: 16.83% conversion (+3,068 drivers)\n",
      "\n",
      "==========================================================================\n",
      "\n",
      "Executive summary saved to 'uber_driver_conversion_summary.md'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from datetime import datetime\n",
    "\n",
    "def generate_recommendations(df, model, feature_importance):\n",
    "    \"\"\"\n",
    "    Generate business recommendations based on the analysis results.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Cleaned dataframe\n",
    "    model: Trained model\n",
    "    feature_importance: DataFrame of feature importances\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    print(\"\\n================= UBER DRIVER CONVERSION RECOMMENDATIONS =================\\n\")\n",
    "    \n",
    "    # 1. Summary of findings\n",
    "    total_drivers = len(df)\n",
    "    converted_drivers = df['started_driving'].sum()\n",
    "    conversion_rate = converted_drivers / total_drivers * 100\n",
    "    \n",
    "    print(f\"EXECUTIVE SUMMARY:\")\n",
    "    print(f\"Analysis of {total_drivers:,} driver signups reveals an overall conversion rate of {conversion_rate:.2f}%\")\n",
    "    print(f\"This means that {converted_drivers:,} drivers completed their first trip, while {total_drivers - converted_drivers:,} did not.\")\n",
    "    print(f\"Based on our analysis, we've identified key factors affecting conversion and developed recommendations.\")\n",
    "    \n",
    "    # 2. Key findings\n",
    "    print(\"\\nKEY FINDINGS:\")\n",
    "    \n",
    "    # BGC completion impact\n",
    "    bgc_completed = df[df['bgc_completed'] == 1]\n",
    "    bgc_conversion = bgc_completed['started_driving'].mean() * 100\n",
    "    print(f\"1. Background Check Completion: Drivers who complete their background check are {bgc_conversion:.1f}x more likely to take their first trip.\")\n",
    "    \n",
    "    # Vehicle addition impact\n",
    "    vehicle_added = df[df['vehicle_added'] == 1]\n",
    "    vehicle_conversion = vehicle_added['started_driving'].mean() * 100\n",
    "    no_vehicle_conversion = df[df['vehicle_added'] == 0]['started_driving'].mean() * 100\n",
    "    vehicle_lift = vehicle_conversion / (no_vehicle_conversion if no_vehicle_conversion > 0 else 1)\n",
    "    print(f\"2. Vehicle Addition: Drivers who add a vehicle are {vehicle_lift:.1f}x more likely to take their first trip.\")\n",
    "    \n",
    "    # Referral channel impact\n",
    "    referral_conversion = df[df['signup_channel'] == 'Referral']['started_driving'].mean() * 100\n",
    "    paid_conversion = df[df['signup_channel'] == 'Paid']['started_driving'].mean() * 100\n",
    "    channel_lift = referral_conversion / paid_conversion\n",
    "    print(f\"3. Signup Channel: Drivers from referrals convert at {referral_conversion:.2f}%, which is {channel_lift:.1f}x better than paid channels.\")\n",
    "    \n",
    "    # Funnel completion\n",
    "    both_steps = df[(df['bgc_completed'] == 1) & (df['vehicle_added'] == 1)]\n",
    "    both_conversion = both_steps['started_driving'].mean() * 100\n",
    "    print(f\"4. Full Funnel Completion: Drivers who complete both BGC and add a vehicle convert at {both_conversion:.2f}%.\")\n",
    "    \n",
    "    # 3. Recommendations\n",
    "    print(\"\\nRECOMMENDATIONS:\")\n",
    "    \n",
    "    # Generate intervention priorities\n",
    "    no_steps = df[(df['bgc_completed'] == 0) & (df['vehicle_added'] == 0)]\n",
    "    bgc_only = df[(df['bgc_completed'] == 1) & (df['vehicle_added'] == 0)]\n",
    "    vehicle_only = df[(df['bgc_completed'] == 0) & (df['vehicle_added'] == 1)]\n",
    "    \n",
    "    print(\"1. Prioritize Vehicle Addition Process\")\n",
    "    print(\"   - The data shows vehicle addition is the strongest predictor of first trips\")\n",
    "    print(\"   - Implement a simplified vehicle registration flow with fewer steps\")\n",
    "    print(\"   - Create guided tutorials for vehicle upload to reduce friction\")\n",
    "    print(\"   - Send targeted reminders to drivers who haven't added vehicle information\")\n",
    "    print(f\"   - Targeting the {len(bgc_only):,} drivers who completed BGC but haven't added a vehicle would yield highest ROI\")\n",
    "    \n",
    "    print(\"\\n2. Streamline Background Check Process\")\n",
    "    print(\"   - Optimize the background check submission workflow to reduce drop-offs\")\n",
    "    print(\"   - Improve communication about the BGC timeline and expectations\")\n",
    "    print(\"   - Implement a progress tracker to encourage completion\")\n",
    "    print(\"   - Send automated reminders with direct links to resume the process\")\n",
    "    \n",
    "    print(\"\\n3. Expand the Referral Program\")\n",
    "    print(f\"   - Referrals convert at {referral_conversion:.2f}%, significantly higher than other channels\")\n",
    "    print(\"   - Consider increasing referral bonuses to generate more referral signups\")\n",
    "    print(\"   - Create a buddy system to pair new drivers with experienced drivers\")\n",
    "    print(\"   - Develop team incentives for referring drivers to help others complete their first trip\")\n",
    "    \n",
    "    print(\"\\n4. Implement Targeted Interventions\")\n",
    "    print(\"   - Use the predictive model to identify drivers most likely to convert\")\n",
    "    print(\"   - Create a tiered re-engagement strategy for stalled applications\")\n",
    "    print(\"   - Pilot a high-touch concierge service for high-potential drivers\")\n",
    "    print(\"   - Develop custom messaging based on where drivers get stuck in the funnel\")\n",
    "    \n",
    "    print(\"\\n5. Improve Paid Channel Quality\")\n",
    "    print(f\"   - Paid channels have the lowest conversion at {paid_conversion:.2f}%\")\n",
    "    print(\"   - Revisit targeting criteria to attract more qualified potential drivers\")\n",
    "    print(\"   - Test different messaging that sets clearer expectations about the process\")\n",
    "    print(\"   - Consider requiring more pre-qualification in paid campaigns\")\n",
    "    \n",
    "    # 4. Implementation roadmap\n",
    "    print(\"\\nIMPLEMENTATION ROADMAP:\")\n",
    "    \n",
    "    current_month = datetime.now().strftime(\"%B %Y\")\n",
    "    \n",
    "    print(f\"Phase 1: Quick Wins (Next 30 Days)\")\n",
    "    print(f\"  • Email/SMS campaign for drivers who completed background checks but haven't added vehicles\")\n",
    "    print(f\"  • Simplify the vehicle information form to require only essential information\")\n",
    "    print(f\"  • Implement progress visualization in the driver app\")\n",
    "    \n",
    "    print(f\"\\nPhase 2: Medium-Term Solutions (60-90 Days)\")\n",
    "    print(f\"  • Develop a predictive intervention system using the model\")\n",
    "    print(f\"  • Redesign the vehicle addition flow with a guided experience\")\n",
    "    print(f\"  • Expand the referral program with new incentives\")\n",
    "    print(f\"  • Create a concierge service pilot for high-potential drivers\")\n",
    "    \n",
    "    print(f\"\\nPhase 3: Longer-Term Initiatives (90+ Days)\")\n",
    "    print(f\"  • Build an integrated onboarding experience with personalized guidance\")\n",
    "    print(f\"  • Develop partnerships to help drivers overcome vehicle barriers\")\n",
    "    print(f\"  • Implement A/B testing program for continuous funnel optimization\")\n",
    "    print(f\"  • Create a driver community platform to facilitate peer support\")\n",
    "    \n",
    "    # 5. Expected impact\n",
    "    current_conversion = conversion_rate / 100\n",
    "    improvement_scenarios = {\n",
    "        'Conservative': current_conversion * 1.15,  # 15% improvement\n",
    "        'Moderate': current_conversion * 1.3,      # 30% improvement\n",
    "        'Aggressive': current_conversion * 1.5      # 50% improvement\n",
    "    }\n",
    "    \n",
    "    print(\"\\nEXPECTED IMPACT:\")\n",
    "    print(f\"Current Driver Conversion: {conversion_rate:.2f}% ({converted_drivers:,} of {total_drivers:,} drivers)\")\n",
    "    \n",
    "    for scenario, new_rate in improvement_scenarios.items():\n",
    "        new_drivers = int(total_drivers * new_rate)\n",
    "        additional_drivers = new_drivers - converted_drivers\n",
    "        print(f\"{scenario} Scenario: {new_rate*100:.2f}% conversion (+{additional_drivers:,} drivers)\")\n",
    "    \n",
    "    print(\"\\n==========================================================================\")\n",
    "    \n",
    "    # Create an impact visualization\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    scenarios = list(improvement_scenarios.keys())\n",
    "    current = ['Current']\n",
    "    all_scenarios = current + scenarios\n",
    "    \n",
    "    rates = [current_conversion * 100] + [improvement_scenarios[s] * 100 for s in scenarios]\n",
    "    drivers = [converted_drivers] + [int(total_drivers * improvement_scenarios[s]) for s in scenarios]\n",
    "    \n",
    "    # Create a bar chart\n",
    "    bars = plt.bar(all_scenarios, rates, color=['#d3d3d3', '#90CAF9', '#42A5F5', '#1976D2'])\n",
    "    \n",
    "    # Add data labels\n",
    "    for i, bar in enumerate(bars):\n",
    "        height = bar.get_height()\n",
    "        additional = ''\n",
    "        if i > 0:\n",
    "            additional = f\" (+{drivers[i] - converted_drivers:,})\"\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "                f\"{rates[i]:.2f}%{additional}\", ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    plt.title('Projected Impact of Recommendations on Driver Conversion Rate')\n",
    "    plt.ylabel('Conversion Rate (%)')\n",
    "    plt.ylim(0, max(rates) * 1.2)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('uber_driver_impact_projections.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Create ROC curve for model evaluation\n",
    "    if model is not None:\n",
    "        try:\n",
    "            # Get probabilities for the positive class\n",
    "            y_true = df['started_driving']\n",
    "            y_proba = model.predict_proba(df[['bgc_completed', 'vehicle_added', 'has_vehicle_info']])[:, 1]\n",
    "            \n",
    "            # Calculate ROC curve\n",
    "            fpr, tpr, thresholds = roc_curve(y_true, y_proba)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            \n",
    "            # Plot ROC curve\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "            plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "            plt.xlim([0.0, 1.0])\n",
    "            plt.ylim([0.0, 1.05])\n",
    "            plt.xlabel('False Positive Rate')\n",
    "            plt.ylabel('True Positive Rate')\n",
    "            plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "            plt.legend(loc=\"lower right\")\n",
    "            plt.grid(alpha=0.3)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig('uber_driver_model_roc_curve.png')\n",
    "            plt.close()\n",
    "        except:\n",
    "            print(\"Note: ROC curve could not be generated with the provided model.\")\n",
    "            \n",
    "    # Generate a summary document\n",
    "    summary = f\"\"\"\n",
    "    # Uber Driver Conversion Analysis - Executive Summary\n",
    "    \n",
    "    Date: {datetime.now().strftime(\"%B %d, %Y\")}\n",
    "    \n",
    "    ## Current Performance\n",
    "    - Total Driver Signups: {total_drivers:,}\n",
    "    - Drivers Completed First Trip: {converted_drivers:,}\n",
    "    - Overall Conversion Rate: {conversion_rate:.2f}%\n",
    "    \n",
    "    ## Key Findings\n",
    "    \n",
    "    1. **Background Check Completion** is a critical step, with drivers who complete it being {bgc_conversion:.1f}x more likely to take their first trip.\n",
    "    \n",
    "    2. **Vehicle Addition** is the strongest predictor of conversion, with a {vehicle_lift:.1f}x lift in conversion rate.\n",
    "    \n",
    "    3. **Referral Channel** produces the highest quality signups, with a conversion rate of {referral_conversion:.2f}%, which is {channel_lift:.1f}x better than paid channels.\n",
    "    \n",
    "    4. **Full Funnel Completion** (both BGC and vehicle) results in a {both_conversion:.2f}% conversion rate.\n",
    "    \n",
    "    ## Top Recommendations\n",
    "    \n",
    "    1. Prioritize Vehicle Addition Process\n",
    "    2. Streamline Background Check Process\n",
    "    3. Expand the Referral Program\n",
    "    4. Implement Targeted Interventions using the Predictive Model\n",
    "    5. Improve Paid Channel Quality\n",
    "    \n",
    "    ## Expected Impact\n",
    "    \n",
    "    - Conservative Scenario: {improvement_scenarios['Conservative']*100:.2f}% conversion (+{int(total_drivers * improvement_scenarios['Conservative']) - converted_drivers:,} drivers)\n",
    "    - Moderate Scenario: {improvement_scenarios['Moderate']*100:.2f}% conversion (+{int(total_drivers * improvement_scenarios['Moderate']) - converted_drivers:,} drivers)\n",
    "    - Aggressive Scenario: {improvement_scenarios['Aggressive']*100:.2f}% conversion (+{int(total_drivers * improvement_scenarios['Aggressive']) - converted_drivers:,} drivers)\n",
    "    \"\"\"\n",
    "    \n",
    "    with open('uber_driver_conversion_summary.md', 'w') as f:\n",
    "        f.write(summary)\n",
    "        \n",
    "    print(\"\\nExecutive summary saved to 'uber_driver_conversion_summary.md'\")\n",
    "\n",
    "# Example of how to use this with the analysis results\n",
    "if __name__ == \"__main__\":\n",
    "    # This would typically be run after the main analysis\n",
    "    # For demonstration, we'll create some dummy data\n",
    "    \n",
    "    # Create dummy DataFrame\n",
    "    data = {\n",
    "        'started_driving': [0] * 48544 + [1] * 6137,\n",
    "        'bgc_completed': [0] * 21785 + [1] * 32896,\n",
    "        'vehicle_added': [0] * 41547 + [1] * 13134,\n",
    "        'has_vehicle_info': [0] * 41458 + [1] * 13223,\n",
    "        'signup_channel': ['Paid'] * 23938 + ['Organic'] * 13427 + ['Referral'] * 17316\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Create dummy feature importance\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': ['vehicle_added', 'has_vehicle_info', 'signup_channel_Paid', \n",
    "                   'signup_channel_Organic', 'signup_channel_Referral', 'bgc_completed'],\n",
    "        'Importance': [1.9754, 1.9339, 1.3977, 1.2730, 0.8387, 0.4630]\n",
    "    })\n",
    "    \n",
    "    # Generate recommendations without a model\n",
    "    generate_recommendations(df, None, feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# Set style for better visualizations\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"viridis\")\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = ['Arial']\n",
    "plt.rcParams['axes.facecolor'] = '#f8f9fa'\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "\n",
    "def create_advanced_visualizations(df):\n",
    "    \"\"\"\n",
    "    Create advanced visualizations for the Uber driver conversion analysis.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Cleaned dataframe\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Create a custom colormap for Uber-like branding\n",
    "    uber_colors = ['#276EF1', '#9CB3FF', '#000000', '#333333']\n",
    "    uber_cmap = LinearSegmentedColormap.from_list('uber', uber_colors)\n",
    "    \n",
    "    # 1. Funnel Visualization\n",
    "    create_conversion_funnel(df)\n",
    "    \n",
    "    # 2. Heatmap of conversion by channel and completion\n",
    "    create_completion_heatmap(df)\n",
    "    \n",
    "    # 3. Driver journey timeline\n",
    "    create_driver_journey_timeline(df)\n",
    "    \n",
    "    # 4. Feature importance visualization\n",
    "    create_feature_importance_chart(df)\n",
    "    \n",
    "    # 5. Conversion prediction calibration\n",
    "    create_conversion_prediction_chart(df)\n",
    "\n",
    "def create_conversion_funnel(df):\n",
    "    \"\"\"Create a conversion funnel visualization.\"\"\"\n",
    "    # Count users at each stage of the funnel\n",
    "    total_signups = len(df)\n",
    "    bgc_completed = df['bgc_completed'].sum()\n",
    "    vehicle_added = df['vehicle_added'].sum()\n",
    "    both_completed = ((df['bgc_completed'] == 1) & (df['vehicle_added'] == 1)).sum()\n",
    "    converted = df['started_driving'].sum()\n",
    "    \n",
    "    # Calculate percentages\n",
    "    bgc_pct = bgc_completed / total_signups * 100\n",
    "    vehicle_pct = vehicle_added / total_signups * 100\n",
    "    both_pct = both_completed / total_signups * 100\n",
    "    converted_pct = converted / total_signups * 100\n",
    "    \n",
    "    # Create the funnel chart\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Define the stages\n",
    "    stages = ['Signups', 'BGC Completed', 'Vehicle Added', 'Both Steps Completed', 'First Trip Completed']\n",
    "    values = [total_signups, bgc_completed, vehicle_added, both_completed, converted]\n",
    "    percentages = [100, bgc_pct, vehicle_pct, both_pct, converted_pct]\n",
    "    \n",
    "    # Plot the funnel\n",
    "    colors = ['#1E88E5', '#42A5F5', '#64B5F6', '#90CAF9', '#BBDEFB']\n",
    "    \n",
    "    # Create bars\n",
    "    y_pos = np.arange(len(stages))\n",
    "    bars = plt.barh(y_pos, percentages, color=colors)\n",
    "    \n",
    "    # Add stage labels\n",
    "    for i, (bar, value, pct) in enumerate(zip(bars, values, percentages)):\n",
    "        plt.text(5, i, f\"{stages[i]}\", va='center', fontweight='bold', fontsize=12, color='black')\n",
    "        plt.text(bar.get_width() + 2, i, f\"{value:,} ({pct:.1f}%)\", va='center')\n",
    "    \n",
    "    # Customize the plot\n",
    "    plt.xlim(0, 105)  # Make room for the percentage labels\n",
    "    plt.yticks([])  # Hide y-axis labels\n",
    "    plt.xlabel('Percentage of Initial Signups')\n",
    "    plt.title('Driver Conversion Funnel', fontsize=14, fontweight='bold', pad=20)\n",
    "    plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Add annotations\n",
    "    drop_after_signup = 100 - bgc_pct\n",
    "    plt.annotate(f'Drop-off: {drop_after_signup:.1f}%', \n",
    "                xy=(50, 0.5), xytext=(50, 0.5 - 0.4),\n",
    "                arrowprops=dict(arrowstyle='->'))\n",
    "    \n",
    "    drop_before_trip = both_pct - converted_pct\n",
    "    plt.annotate(f'Drop-off: {drop_before_trip:.1f}%', \n",
    "                xy=(50, 3.5), xytext=(50, 3.5 - 0.4),\n",
    "                arrowprops=dict(arrowstyle='->'))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('uber_driver_conversion_funnel.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def create_completion_heatmap(df):\n",
    "    \"\"\"Create a heatmap of conversion rates by channel and completion status.\"\"\"\n",
    "    # Create cross-tabulation of conversion rate by channel and funnel status\n",
    "    crosstab_data = []\n",
    "    for channel in df['signup_channel'].unique():\n",
    "        for bgc in [0, 1]:\n",
    "            for vehicle in [0, 1]:\n",
    "                filtered = df[(df['signup_channel'] == channel) & \n",
    "                            (df['bgc_completed'] == bgc) & \n",
    "                            (df['vehicle_added'] == vehicle)]\n",
    "                \n",
    "                if len(filtered) > 0:\n",
    "                    conversion_rate = filtered['started_driving'].mean() * 100\n",
    "                    count = len(filtered)\n",
    "                    crosstab_data.append({\n",
    "                        'Channel': channel,\n",
    "                        'BGC': 'Completed' if bgc == 1 else 'Not Completed',\n",
    "                        'Vehicle': 'Added' if vehicle == 1 else 'Not Added',\n",
    "                        'Conversion': conversion_rate,\n",
    "                        'Count': count\n",
    "                    })\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    crosstab_df = pd.DataFrame(crosstab_data)\n",
    "    \n",
    "    # Pivot for the heatmap\n",
    "    heatmap_data = crosstab_df.pivot_table(\n",
    "        index=['Channel', 'BGC'],\n",
    "        columns='Vehicle',\n",
    "        values='Conversion',\n",
    "        aggfunc='mean'\n",
    "    ).fillna(0)\n",
    "    \n",
    "    # Count pivot for annotations\n",
    "    count_data = crosstab_df.pivot_table(\n",
    "        index=['Channel', 'BGC'],\n",
    "        columns='Vehicle',\n",
    "        values='Count',\n",
    "        aggfunc='sum'\n",
    "    ).fillna(0)\n",
    "    \n",
    "    # Create a figure\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    \n",
    "    # Create heatmap\n",
    "    ax = sns.heatmap(heatmap_data, annot=True, fmt='.1f', cmap='YlGnBu', \n",
    "                   linewidths=.5, annot_kws={\"size\": 10})\n",
    "    \n",
    "    # Add count annotations\n",
    "    for i, idx in enumerate(heatmap_data.index):\n",
    "        for j, col in enumerate(heatmap_data.columns):\n",
    "            count = count_data.loc[idx, col]\n",
    "            plt.text(j+0.5, i+0.7, f\"n={count:,}\", ha='center', va='center', \n",
    "                   color='black', fontsize=8)\n",
    "    \n",
    "    # Customize the plot\n",
    "    plt.title('Driver Conversion Rate (%) by Channel, BGC, and Vehicle Status', \n",
    "             fontsize=14, fontweight='bold', pad=20)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('uber_driver_conversion_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def create_driver_journey_timeline(df):\n",
    "    \"\"\"Create a visualization of the driver journey timeline.\"\"\"\n",
    "    # Filter only converted drivers with complete data\n",
    "    timeline_df = df[(df['started_driving'] == 1) & \n",
    "                    (~df['days_to_bgc'].isnull()) & \n",
    "                    (~df['days_to_vehicle'].isnull()) & \n",
    "                    (~df['days_to_first_trip'].isnull())].copy()\n",
    "    \n",
    "    if len(timeline_df) == 0:\n",
    "        return  # Not enough data\n",
    "    \n",
    "    # Calculate average days for each milestone\n",
    "    avg_to_bgc = timeline_df['days_to_bgc'].median()\n",
    "    avg_to_vehicle = timeline_df['days_to_vehicle'].median()\n",
    "    avg_to_trip = timeline_df['days_to_first_trip'].median()\n",
    "    \n",
    "    # Create bins for time to first trip\n",
    "    timeline_df['time_to_trip_category'] = pd.cut(\n",
    "        timeline_df['days_to_first_trip'],\n",
    "        bins=[0, 1, 3, 7, 14, 30, float('inf')],\n",
    "        labels=['Same day', '1-3 days', '4-7 days', '8-14 days', '15-30 days', '30+ days']\n",
    "    )\n",
    "    \n",
    "    trip_time_dist = timeline_df['time_to_trip_category'].value_counts(normalize=True) * 100\n",
    "    \n",
    "    # Create the figure\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10), gridspec_kw={'height_ratios': [1, 2]})\n",
    "    \n",
    "    # Plot 1: Timeline\n",
    "    milestones = ['Signup', 'BGC Completion', 'Vehicle Addition', 'First Trip']\n",
    "    days = [0, avg_to_bgc, avg_to_vehicle, avg_to_trip]\n",
    "    \n",
    "    ax1.plot(days, [1, 1, 1, 1], 'o-', markersize=10, linewidth=2, color='#1976D2')\n",
    "    \n",
    "    # Add milestone labels\n",
    "    for i, (milestone, day) in enumerate(zip(milestones, days)):\n",
    "        ax1.annotate(f\"{milestone}\\nDay {day:.1f}\", \n",
    "                   (day, 1), \n",
    "                   xytext=(0, 20), \n",
    "                   textcoords='offset points',\n",
    "                   ha='center', \n",
    "                   fontweight='bold' if i == 0 or i == 3 else 'normal')\n",
    "    \n",
    "    # Configure the timeline\n",
    "    ax1.set_ylim(0.5, 1.5)\n",
    "    ax1.set_yticks([])\n",
    "    ax1.set_xlabel('Days Since Signup')\n",
    "    ax1.set_title('Driver Journey Timeline (Median Days)', fontsize=14, fontweight='bold')\n",
    "    ax1.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Plot 2: Distribution of time to first trip\n",
    "    sns.barplot(x=trip_time_dist.index, y=trip_time_dist.values, ax=ax2, color='#64B5F6')\n",
    "    \n",
    "    # Add percentage labels\n",
    "    for i, v in enumerate(trip_time_dist.values):\n",
    "        ax2.text(i, v + 1, f\"{v:.1f}%\", ha='center')\n",
    "    \n",
    "    ax2.set_xticklabels(ax2.get_xticklabels(), rotation=45)\n",
    "    ax2.set_title('Distribution of Time to First Trip', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xlabel('Time to First Trip')\n",
    "    ax2.set_ylabel('Percentage of Converted Drivers')\n",
    "    ax2.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('uber_driver_journey_timeline.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def create_feature_importance_chart(df):\n",
    "    \"\"\"Create a feature importance visualization based on conversion lift.\"\"\"\n",
    "    # Calculate lift for key features\n",
    "    base_conversion = df['started_driving'].mean() * 100\n",
    "    \n",
    "    # Calculate lift for each feature\n",
    "    feature_lifts = []\n",
    "    \n",
    "    # BGC completion\n",
    "    bgc_conversion = df[df['bgc_completed'] == 1]['started_driving'].mean() * 100\n",
    "    bgc_lift = bgc_conversion / base_conversion\n",
    "    feature_lifts.append(('Background Check\\nCompleted', bgc_lift))\n",
    "    \n",
    "    # Vehicle addition\n",
    "    vehicle_conversion = df[df['vehicle_added'] == 1]['started_driving'].mean() * 100\n",
    "    vehicle_lift = vehicle_conversion / base_conversion\n",
    "    feature_lifts.append(('Vehicle\\nAdded', vehicle_lift))\n",
    "    \n",
    "    # Referral channel\n",
    "    referral_conversion = df[df['signup_channel'] == 'Referral']['started_driving'].mean() * 100\n",
    "    referral_lift = referral_conversion / base_conversion\n",
    "    feature_lifts.append(('Referral\\nChannel', referral_lift))\n",
    "    \n",
    "    # Organic channel\n",
    "    organic_conversion = df[df['signup_channel'] == 'Organic']['started_driving'].mean() * 100\n",
    "    organic_lift = organic_conversion / base_conversion\n",
    "    feature_lifts.append(('Organic\\nChannel', organic_lift))\n",
    "    \n",
    "    # Both steps completed\n",
    "    both_conversion = df[(df['bgc_completed'] == 1) & (df['vehicle_added'] == 1)]['started_driving'].mean() * 100\n",
    "    both_lift = both_conversion / base_conversion\n",
    "    feature_lifts.append(('Both BGC &\\nVehicle', both_lift))\n",
    "    \n",
    "    # Create DataFrame\n",
    "    lift_df = pd.DataFrame(feature_lifts, columns=['Feature', 'Lift'])\n",
    "    lift_df = lift_df.sort_values('Lift', ascending=False)\n",
    "    \n",
    "    # Create the chart\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(lift_df['Feature'], lift_df['Lift'], color='#42A5F5')\n",
    "    \n",
    "    # Add baseline\n",
    "    plt.axhline(y=1, color='red', linestyle='--', label='Baseline')\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
    "                f\"{height:.1f}x\", ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    plt.title('Conversion Rate Lift by Feature', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('Lift Multiple (Compared to Baseline)')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('uber_driver_conversion_lift.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def create_conversion_prediction_chart(df):\n",
    "    \"\"\"Create a chart showing predicted conversion based on completed steps.\"\"\"\n",
    "    # Calculate probability of conversion based on funnel stage\n",
    "    stages = []\n",
    "    \n",
    "    # No steps\n",
    "    no_steps_conv = df[(df['bgc_completed'] == 0) & (df['vehicle_added'] == 0)]['started_driving'].mean() * 100\n",
    "    no_steps_count = len(df[(df['bgc_completed'] == 0) & (df['vehicle_added'] == 0)])\n",
    "    stages.append(('No Steps\\nCompleted', no_steps_conv, no_steps_count))\n",
    "    \n",
    "    # BGC only\n",
    "    bgc_only_conv = df[(df['bgc_completed'] == 1) & (df['vehicle_added'] == 0)]['started_driving'].mean() * 100\n",
    "    bgc_only_count = len(df[(df['bgc_completed'] == 1) & (df['vehicle_added'] == 0)])\n",
    "    stages.append(('BGC Only', bgc_only_conv, bgc_only_count))\n",
    "    \n",
    "    # Vehicle only\n",
    "    vehicle_only_conv = df[(df['bgc_completed'] == 0) & (df['vehicle_added'] == 1)]['started_driving'].mean() * 100\n",
    "    vehicle_only_count = len(df[(df['bgc_completed'] == 0) & (df['vehicle_added'] == 1)])\n",
    "    stages.append(('Vehicle Only', vehicle_only_conv, vehicle_only_count))\n",
    "    \n",
    "    # Both steps\n",
    "    both_conv = df[(df['bgc_completed'] == 1) & (df['vehicle_added'] == 1)]['started_driving'].mean() * 100\n",
    "    both_count = len(df[(df['bgc_completed'] == 1) & (df['vehicle_added'] == 1)])\n",
    "    stages.append(('Both BGC &\\nVehicle', both_conv, both_count))\n",
    "    \n",
    "    # Create DataFrame\n",
    "    stages_df = pd.DataFrame(stages, columns=['Stage', 'Conversion', 'Count'])\n",
    "    \n",
    "    # Create the chart\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Create gradient colors based on conversion rate\n",
    "    norm = plt.Normalize(stages_df['Conversion'].min(), stages_df['Conversion'].max())\n",
    "    colors = plt.cm.viridis(norm(stages_df['Conversion']))\n",
    "    \n",
    "    # Create bars with counts as width\n",
    "    bars = plt.bar(stages_df['Stage'], stages_df['Conversion'], color=colors)\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, bar in enumerate(bars):\n",
    "        height = bar.get_height()\n",
    "        count = stages_df.iloc[i]['Count']\n",
    "        pct_of_total = count / len(df) * 100\n",
    "        \n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                f\"{height:.1f}%\", ha='center', va='bottom', fontweight='bold')\n",
    "        \n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height/2,\n",
    "                f\"n={count:,}\\n({pct_of_total:.1f}% of total)\", \n",
    "                ha='center', va='center', color='white' if height > 20 else 'black',\n",
    "                fontweight='bold')\n",
    "    \n",
    "    plt.title('Conversion Rate by Funnel Stage', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('Conversion Rate (%)')\n",
    "    plt.ylim(0, stages_df['Conversion'].max() * 1.2)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Add annotations for key insights\n",
    "    if both_conv > 0:\n",
    "        plt.annotate(f\"{both_conv:.1f}% conversion when\\nboth steps completed\",\n",
    "                   xy=(3, both_conv), xytext=(3.3, both_conv * 0.7),\n",
    "                   arrowprops=dict(arrowstyle='->', color='black'))\n",
    "    \n",
    "    # Add \"opportunity\" annotation\n",
    "    for i, row in stages_df.iterrows():\n",
    "        if row['Stage'] == 'BGC Only' and row['Count'] > 1000:\n",
    "            plt.annotate(\"Major opportunity:\\nHelp these drivers\\nadd vehicles\",\n",
    "                       xy=(i, row['Conversion']), xytext=(i - 0.5, row['Conversion'] + 20),\n",
    "                       arrowprops=dict(arrowstyle='->', color='red'))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('uber_driver_stage_conversion.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# Sample execution code\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a sample dataset based on the statistics we've observed\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Create data for 54,681 drivers\n",
    "    n_drivers = 54681\n",
    "    \n",
    "    # Create BGC and vehicle statuses based on observed proportions\n",
    "    bgc_completed = np.zeros(n_drivers, dtype=int)\n",
    "    bgc_completed[:32896] = 1\n",
    "    \n",
    "    vehicle_added = np.zeros(n_drivers, dtype=int)\n",
    "    vehicle_added[:13134] = 1\n",
    "    \n",
    "    # Shuffle to ensure random distribution\n",
    "    np.random.shuffle(bgc_completed)\n",
    "    np.random.shuffle(vehicle_added)\n",
    "    \n",
    "    # Create signup channel values\n",
    "    channels = np.empty(n_drivers, dtype=object)\n",
    "    channels[:23938] = 'Paid'\n",
    "    channels[23938:23938+13427] = 'Organic'\n",
    "    channels[23938+13427:] = 'Referral'\n",
    "    np.random.shuffle(channels)\n",
    "    \n",
    "    # Create the started_driving target variable based on combinations\n",
    "    started_driving = np.zeros(n_drivers, dtype=int)\n",
    "    \n",
    "    # For BGC & vehicle completed, ~45% conversion rate\n",
    "    both_indices = np.where((bgc_completed == 1) & (vehicle_added == 1))[0]\n",
    "    conversion_mask = np.random.random(len(both_indices)) < 0.456\n",
    "    started_driving[both_indices[conversion_mask]] = 1\n",
    "    \n",
    "    # For BGC only, ~1.3% conversion rate\n",
    "    bgc_only_indices = np.where((bgc_completed == 1) & (vehicle_added == 0))[0]\n",
    "    conversion_mask = np.random.random(len(bgc_only_indices)) < 0.013\n",
    "    started_driving[bgc_only_indices[conversion_mask]] = 1\n",
    "    \n",
    "    # For vehicle only, ~0% conversion rate (negligible)\n",
    "    \n",
    "    # For referral channel, boost conversion slightly\n",
    "    referral_indices = np.where(channels == 'Referral')[0]\n",
    "    referral_boost_indices = np.random.choice(\n",
    "        referral_indices, \n",
    "        size=int(len(referral_indices) * 0.05), \n",
    "        replace=False\n",
    "    )\n",
    "    started_driving[referral_boost_indices] = 1\n",
    "    \n",
    "    # Ensure the total conversion rate is around 11.22%\n",
    "    total_converted = started_driving.sum()\n",
    "    target_converted = int(n_drivers * 0.1122)\n",
    "    \n",
    "    if total_converted < target_converted:\n",
    "        # Need to convert more\n",
    "        not_converted = np.where(started_driving == 0)[0]\n",
    "        to_convert = np.random.choice(\n",
    "            not_converted,\n",
    "            size=target_converted - total_converted,\n",
    "            replace=False\n",
    "        )\n",
    "        started_driving[to_convert] = 1\n",
    "    elif total_converted > target_converted:\n",
    "        # Need to unconvert some\n",
    "        converted = np.where(started_driving == 1)[0]\n",
    "        to_unconvert = np.random.choice(\n",
    "            converted,\n",
    "            size=total_converted - target_converted,\n",
    "            replace=False\n",
    "        )\n",
    "        started_driving[to_unconvert] = 0\n",
    "    \n",
    "    # Create time-related features\n",
    "    days_to_bgc = np.zeros(n_drivers)\n",
    "    days_to_vehicle = np.zeros(n_drivers)\n",
    "    days_to_first_trip = np.zeros(n_drivers)\n",
    "    \n",
    "    # For drivers who completed BGC\n",
    "    bgc_indices = np.where(bgc_completed == 1)[0]\n",
    "    days_to_bgc[bgc_indices] = np.random.exponential(scale=5, size=len(bgc_indices))\n",
    "    \n",
    "    # For drivers who added vehicles\n",
    "    vehicle_indices = np.where(vehicle_added == 1)[0]\n",
    "    days_to_vehicle[vehicle_indices] = np.random.exponential(scale=7, size=len(vehicle_indices))\n",
    "    \n",
    "    # For drivers who started driving\n",
    "    converted_indices = np.where(started_driving == 1)[0]\n",
    "    days_to_first_trip[converted_indices] = np.maximum(\n",
    "        days_to_bgc[converted_indices],\n",
    "        days_to_vehicle[converted_indices]\n",
    "    ) + np.random.exponential(scale=3, size=len(converted_indices))\n",
    "    \n",
    "    # Create the dataframe\n",
    "    df = pd.DataFrame({\n",
    "        'started_driving': started_driving,\n",
    "        'bgc_completed': bgc_completed,\n",
    "        'vehicle_added': vehicle_added,\n",
    "        'has_vehicle_info': vehicle_added,  # Simplified assumption\n",
    "        'signup_channel': channels,\n",
    "        'days_to_bgc': days_to_bgc,\n",
    "        'days_to_vehicle': days_to_vehicle,\n",
    "        'days_to_first_trip': days_to_first_trip\n",
    "    })\n",
    "    \n",
    "    # Create all visualizations\n",
    "    create_advanced_visualizations(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing data...\n",
      "\n",
      "Building and evaluating models...\n",
      "Training Logistic Regression...\n",
      "Accuracy: 0.8650\n",
      "Precision: 0.4533\n",
      "Recall: 0.9603\n",
      "F1 Score: 0.6159\n",
      "ROC AUC: 0.9555\n",
      "PR AUC: 0.7101\n",
      "Confusion Matrix:\n",
      "[[8276 1428]\n",
      " [  49 1184]]\n",
      "\n",
      "\n",
      "Training Random Forest...\n",
      "Accuracy: 0.8901\n",
      "Precision: 0.5078\n",
      "Recall: 0.8216\n",
      "F1 Score: 0.6276\n",
      "ROC AUC: 0.9241\n",
      "PR AUC: 0.6340\n",
      "Confusion Matrix:\n",
      "[[8722  982]\n",
      " [ 220 1013]]\n",
      "\n",
      "\n",
      "Training Gradient Boosting...\n",
      "Accuracy: 0.9273\n",
      "Precision: 0.7086\n",
      "Recall: 0.6034\n",
      "F1 Score: 0.6518\n",
      "ROC AUC: 0.9574\n",
      "PR AUC: 0.7273\n",
      "Confusion Matrix:\n",
      "[[9398  306]\n",
      " [ 489  744]]\n",
      "\n",
      "\n",
      "Logistic Regression Feature Importance:\n",
      "                    Feature  Importance\n",
      "13            bgc_completed    5.547618\n",
      "15         has_vehicle_info    2.739734\n",
      "14            vehicle_added    2.169721\n",
      "17    bgc_completed_quickly    1.093051\n",
      "16    vehicle_added_quickly    1.039791\n",
      "18       bgc_before_vehicle    0.931140\n",
      "9          city_name_Berton    0.505974\n",
      "6           signup_os_other    0.446545\n",
      "2   signup_channel_Referral    0.370969\n",
      "3     signup_os_android web    0.310271\n",
      "\n",
      "Random Forest Feature Importance (Permutation):\n",
      "                 Feature  Importance\n",
      "4  bgc_completed_quickly    0.009573\n",
      "5     bgc_before_vehicle    0.006601\n",
      "3  vehicle_added_quickly    0.003209\n",
      "6         signup_channel    0.002048\n",
      "8              city_name    0.001509\n",
      "7              signup_os    0.000713\n",
      "0          bgc_completed   -0.003145\n",
      "2       has_vehicle_info   -0.006775\n",
      "9            vehicle_age   -0.011182\n",
      "1          vehicle_added   -0.017528\n",
      "\n",
      "Visualizing model results...\n",
      "\n",
      "Best model: Gradient Boosting (F1: 0.6518)\n",
      "\n",
      "Tuning the best model...\n",
      "Tuning Gradient Boosting...\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Best parameters: {'classifier__learning_rate': 0.1, 'classifier__max_depth': 5, 'classifier__n_estimators': 100, 'classifier__subsample': 1.0}\n",
      "Best cross-validation score: 0.6767\n",
      "\n",
      "Test set performance:\n",
      "Accuracy: 0.9293\n",
      "Precision: 0.7007\n",
      "Recall: 0.6513\n",
      "F1 Score: 0.6751\n",
      "Confusion Matrix:\n",
      "[[9361  343]\n",
      " [ 430  803]]\n",
      "\n",
      "Analysis complete. Visualizations saved to files.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, \n",
    "    confusion_matrix, classification_report, roc_curve, auc, \n",
    "    precision_recall_curve, average_precision_score\n",
    ")\n",
    "from sklearn.inspection import permutation_importance\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def load_and_prepare_data(file_path):\n",
    "    \"\"\"\n",
    "    Load and prepare the data for modeling.\n",
    "    \n",
    "    Parameters:\n",
    "    file_path (str): Path to the CSV file\n",
    "    \n",
    "    Returns:\n",
    "    tuple: X, y, feature_names\n",
    "    \"\"\"\n",
    "    # Read the data\n",
    "    df = pd.read_csv(file_path, na_values=\"NA\")\n",
    "    \n",
    "    # Convert date columns to datetime\n",
    "    date_columns = ['signup_date', 'bgc_date', 'vehicle_added_date', 'first_completed_date']\n",
    "    for col in date_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "    \n",
    "    # Create target variable: did the driver take their first trip?\n",
    "    df['started_driving'] = (~df['first_completed_date'].isna()).astype(int)\n",
    "    \n",
    "    # Create binary features for key steps\n",
    "    df['bgc_completed'] = (~df['bgc_date'].isna()).astype(int)\n",
    "    df['vehicle_added'] = (~df['vehicle_added_date'].isna()).astype(int)\n",
    "    df['has_vehicle_info'] = (~df['vehicle_make'].isna()).astype(int)\n",
    "    \n",
    "    # Calculate days between signup and other events\n",
    "    df['days_to_bgc'] = (df['bgc_date'] - df['signup_date']).dt.days\n",
    "    df['days_to_vehicle'] = (df['vehicle_added_date'] - df['signup_date']).dt.days\n",
    "    \n",
    "    # Fill NA values for days with high values (indicating not completed)\n",
    "    df['days_to_bgc'] = df['days_to_bgc'].fillna(999)\n",
    "    df['days_to_vehicle'] = df['days_to_vehicle'].fillna(999)\n",
    "    \n",
    "    # Feature for whether vehicle was added quickly (within 3 days)\n",
    "    df['vehicle_added_quickly'] = ((df['days_to_vehicle'] >= 0) & (df['days_to_vehicle'] <= 3)).astype(int)\n",
    "    \n",
    "    # Feature for whether BGC was completed quickly (within 3 days)\n",
    "    df['bgc_completed_quickly'] = ((df['days_to_bgc'] >= 0) & (df['days_to_bgc'] <= 3)).astype(int)\n",
    "    \n",
    "    # Create feature for BGC completed before vehicle added\n",
    "    df['bgc_before_vehicle'] = ((df['bgc_completed'] == 1) & \n",
    "                              (df['vehicle_added'] == 1) & \n",
    "                              (df['days_to_bgc'] < df['days_to_vehicle'])).astype(int)\n",
    "    \n",
    "    # Create a feature for vehicle age (current year - vehicle year)\n",
    "    if 'vehicle_year' in df.columns:\n",
    "        current_year = pd.Timestamp.now().year\n",
    "        df['vehicle_age'] = current_year - df['vehicle_year']\n",
    "        df['vehicle_age'] = df['vehicle_age'].clip(0, 25)  # Clip to sensible range\n",
    "        df['vehicle_age'] = df['vehicle_age'].fillna(-1)  # -1 indicates no vehicle\n",
    "    \n",
    "    # Select features for the model\n",
    "    feature_columns = [\n",
    "        'bgc_completed', 'vehicle_added', 'has_vehicle_info',\n",
    "        'vehicle_added_quickly', 'bgc_completed_quickly', 'bgc_before_vehicle',\n",
    "        'signup_channel', 'signup_os', 'city_name'\n",
    "    ]\n",
    "    \n",
    "    if 'vehicle_age' in df.columns:\n",
    "        feature_columns.append('vehicle_age')\n",
    "    \n",
    "    X = df[feature_columns]\n",
    "    y = df['started_driving']\n",
    "    \n",
    "    return X, y, feature_columns\n",
    "\n",
    "def build_and_evaluate_models(X, y, feature_names):\n",
    "    \"\"\"\n",
    "    Build and evaluate multiple models for predicting driver conversion.\n",
    "    \n",
    "    Parameters:\n",
    "    X: Features\n",
    "    y: Target variable\n",
    "    feature_names: List of feature names\n",
    "    \n",
    "    Returns:\n",
    "    dict: Trained models\n",
    "    \"\"\"\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Create preprocessing pipeline\n",
    "    numeric_features = [col for col in X.columns if X[col].dtype in ['int64', 'float64'] \n",
    "                      and col not in ['bgc_completed', 'vehicle_added', 'has_vehicle_info',\n",
    "                                    'vehicle_added_quickly', 'bgc_completed_quickly', 'bgc_before_vehicle']]\n",
    "    \n",
    "    binary_features = ['bgc_completed', 'vehicle_added', 'has_vehicle_info',\n",
    "                     'vehicle_added_quickly', 'bgc_completed_quickly', 'bgc_before_vehicle']\n",
    "    \n",
    "    categorical_features = [col for col in X.columns if X[col].dtype == 'object']\n",
    "    \n",
    "    # Define preprocessors\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ],\n",
    "        remainder='passthrough'  # Include binary features as-is\n",
    "    )\n",
    "    \n",
    "    # Create model pipelines\n",
    "    models = {\n",
    "        'Logistic Regression': Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', LogisticRegression(max_iter=1000, class_weight='balanced'))\n",
    "        ]),\n",
    "        \n",
    "        'Random Forest': Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42))\n",
    "        ]),\n",
    "        \n",
    "        'Gradient Boosting': Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', GradientBoostingClassifier(n_estimators=100, random_state=42))\n",
    "        ])\n",
    "    }\n",
    "    \n",
    "    # Train and evaluate each model\n",
    "    results = {}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        print(f\"Training {name}...\")\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        \n",
    "        # ROC AUC\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        \n",
    "        # Precision-Recall AUC\n",
    "        precision_curve, recall_curve, _ = precision_recall_curve(y_test, y_prob)\n",
    "        pr_auc = average_precision_score(y_test, y_prob)\n",
    "        \n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1 Score: {f1:.4f}\")\n",
    "        print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "        print(f\"PR AUC: {pr_auc:.4f}\")\n",
    "        print(f\"Confusion Matrix:\")\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        # Store results\n",
    "        results[name] = {\n",
    "            'model': model,\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1,\n",
    "            'roc_auc': roc_auc,\n",
    "            'pr_auc': pr_auc,\n",
    "            'fpr': fpr,\n",
    "            'tpr': tpr,\n",
    "            'precision_curve': precision_curve,\n",
    "            'recall_curve': recall_curve,\n",
    "            'y_prob': y_prob\n",
    "        }\n",
    "    \n",
    "    # Get feature importances\n",
    "    try:\n",
    "        # For logistic regression\n",
    "        logistic_model = models['Logistic Regression'].named_steps['classifier']\n",
    "        \n",
    "        # Get the feature names after preprocessing\n",
    "        preprocessor = models['Logistic Regression'].named_steps['preprocessor']\n",
    "        cat_features = preprocessor.transformers_[1][1].named_steps['onehot'].get_feature_names_out(categorical_features)\n",
    "        all_features = list(cat_features) + numeric_features + binary_features\n",
    "        \n",
    "        # Get coefficients\n",
    "        coefs = logistic_model.coef_[0]\n",
    "        \n",
    "        # Create DataFrame of feature importance\n",
    "        lr_importance = pd.DataFrame({\n",
    "            'Feature': all_features,\n",
    "            'Importance': np.abs(coefs)\n",
    "        }).sort_values('Importance', ascending=False)\n",
    "        \n",
    "        print(\"Logistic Regression Feature Importance:\")\n",
    "        print(lr_importance.head(10))\n",
    "        \n",
    "        results['feature_importance'] = lr_importance\n",
    "    except:\n",
    "        print(\"Could not extract Logistic Regression feature importance.\")\n",
    "    \n",
    "    try:\n",
    "        # For Random Forest\n",
    "        rf_model = models['Random Forest'].named_steps['classifier']\n",
    "        result = permutation_importance(models['Random Forest'], X_test, y_test, n_repeats=10, random_state=42)\n",
    "        rf_importance = pd.DataFrame({\n",
    "            'Feature': X.columns,\n",
    "            'Importance': result.importances_mean\n",
    "        }).sort_values('Importance', ascending=False)\n",
    "        \n",
    "        print(\"\\nRandom Forest Feature Importance (Permutation):\")\n",
    "        print(rf_importance.head(10))\n",
    "        \n",
    "        results['rf_importance'] = rf_importance\n",
    "    except:\n",
    "        print(\"Could not extract Random Forest feature importance.\")\n",
    "    \n",
    "    return results, X_test, y_test\n",
    "\n",
    "def visualize_model_results(results, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Visualize the model comparison results.\n",
    "    \n",
    "    Parameters:\n",
    "    results: Dictionary of model results\n",
    "    X_test: Test features\n",
    "    y_test: Test target\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Create a figure for model comparison\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    \n",
    "    # Plot 1: ROC curves\n",
    "    plt.subplot(2, 2, 1)\n",
    "    for name, result in results.items():\n",
    "        if name not in ['feature_importance', 'rf_importance']:\n",
    "            plt.plot(result['fpr'], result['tpr'], label=f\"{name} (AUC = {result['roc_auc']:.3f})\")\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curves')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Precision-Recall curves\n",
    "    plt.subplot(2, 2, 2)\n",
    "    for name, result in results.items():\n",
    "        if name not in ['feature_importance', 'rf_importance']:\n",
    "            plt.plot(result['recall_curve'], result['precision_curve'], label=f\"{name} (AUC = {result['pr_auc']:.3f})\")\n",
    "    \n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curves')\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Model comparison metrics\n",
    "    plt.subplot(2, 2, 3)\n",
    "    model_names = [name for name in results if name not in ['feature_importance', 'rf_importance']]\n",
    "    metrics = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc', 'pr_auc']\n",
    "    metrics_display = ['Accuracy', 'Precision', 'Recall', 'F1', 'ROC AUC', 'PR AUC']\n",
    "    \n",
    "    # Create a dataframe for the metrics\n",
    "    metrics_data = []\n",
    "    for name in model_names:\n",
    "        for metric in metrics:\n",
    "            metrics_data.append({\n",
    "                'Model': name,\n",
    "                'Metric': metrics_display[metrics.index(metric)],\n",
    "                'Value': results[name][metric]\n",
    "            })\n",
    "    \n",
    "    metrics_df = pd.DataFrame(metrics_data)\n",
    "    \n",
    "    # Plot the metrics\n",
    "    sns.barplot(x='Metric', y='Value', hue='Model', data=metrics_df)\n",
    "    plt.title('Model Performance Comparison')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.legend(title='Model')\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Plot 4: Feature importance\n",
    "    plt.subplot(2, 2, 4)\n",
    "    \n",
    "    if 'feature_importance' in results:\n",
    "        top_features = results['feature_importance'].head(10)\n",
    "        sns.barplot(x='Importance', y='Feature', data=top_features)\n",
    "        plt.title('Top 10 Feature Importances (Logistic Regression)')\n",
    "        plt.grid(axis='x', alpha=0.3)\n",
    "    elif 'rf_importance' in results:\n",
    "        top_features = results['rf_importance'].head(10)\n",
    "        sns.barplot(x='Importance', y='Feature', data=top_features)\n",
    "        plt.title('Top 10 Feature Importances (Random Forest)')\n",
    "        plt.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('uber_driver_model_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Create a figure for prediction distribution\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    for i, name in enumerate(model_names):\n",
    "        plt.subplot(1, len(model_names), i+1)\n",
    "        \n",
    "        # Extract predictions\n",
    "        y_prob = results[name]['y_prob']\n",
    "        \n",
    "        # Plot distributions\n",
    "        sns.histplot(y_prob[y_test == 0], bins=20, alpha=0.5, label='Did not convert', color='red')\n",
    "        sns.histplot(y_prob[y_test == 1], bins=20, alpha=0.5, label='Converted', color='green')\n",
    "        \n",
    "        plt.title(f'{name} Prediction Distribution')\n",
    "        plt.xlabel('Predicted Probability')\n",
    "        plt.ylabel('Count')\n",
    "        plt.legend()\n",
    "        plt.grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('uber_driver_prediction_distribution.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Create a calibration curve\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    for name in model_names:\n",
    "        # Create bins for calibration\n",
    "        y_prob = results[name]['y_prob']\n",
    "        bins = np.linspace(0, 1, 11)\n",
    "        bin_midpoints = (bins[1:] + bins[:-1]) / 2\n",
    "        bin_indices = np.digitize(y_prob, bins) - 1\n",
    "        bin_indices = np.clip(bin_indices, 0, len(bins) - 2)\n",
    "        \n",
    "        bin_sums = np.bincount(bin_indices, minlength=len(bins) - 1)\n",
    "        bin_true = np.bincount(bin_indices, weights=y_test, minlength=len(bins) - 1)\n",
    "        bin_props = np.zeros(len(bins) - 1)\n",
    "        \n",
    "        nonzero = bin_sums > 0\n",
    "        bin_props[nonzero] = bin_true[nonzero] / bin_sums[nonzero]\n",
    "        \n",
    "        plt.plot(bin_midpoints, bin_props, 'o-', label=name)\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='Perfect Calibration')\n",
    "    plt.xlabel('Predicted Probability')\n",
    "    plt.ylabel('Actual Probability')\n",
    "    plt.title('Calibration Curves')\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('uber_driver_calibration_curves.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def tune_best_model(X, y, best_model_name):\n",
    "    \"\"\"\n",
    "    Tune the hyperparameters of the best model.\n",
    "    \n",
    "    Parameters:\n",
    "    X: Features\n",
    "    y: Target variable\n",
    "    best_model_name: Name of the best model\n",
    "    \n",
    "    Returns:\n",
    "    dict: Best parameter settings\n",
    "    \"\"\"\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Create preprocessing pipeline\n",
    "    numeric_features = [col for col in X.columns if X[col].dtype in ['int64', 'float64'] \n",
    "                      and col not in ['bgc_completed', 'vehicle_added', 'has_vehicle_info',\n",
    "                                    'vehicle_added_quickly', 'bgc_completed_quickly', 'bgc_before_vehicle']]\n",
    "    \n",
    "    binary_features = ['bgc_completed', 'vehicle_added', 'has_vehicle_info',\n",
    "                     'vehicle_added_quickly', 'bgc_completed_quickly', 'bgc_before_vehicle']\n",
    "    \n",
    "    categorical_features = [col for col in X.columns if X[col].dtype == 'object']\n",
    "    \n",
    "    # Define preprocessors\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ],\n",
    "        remainder='passthrough'  # Include binary features as-is\n",
    "    )\n",
    "    \n",
    "    # Define parameter grids for each model\n",
    "    param_grids = {\n",
    "        'Logistic Regression': {\n",
    "            'classifier__C': [0.01, 0.1, 1, 10, 100],\n",
    "            'classifier__penalty': ['l1', 'l2'],\n",
    "            'classifier__solver': ['liblinear', 'saga'],\n",
    "            'classifier__class_weight': ['balanced', None]\n",
    "        },\n",
    "        \n",
    "        'Random Forest': {\n",
    "            'classifier__n_estimators': [50, 100, 200],\n",
    "            'classifier__max_depth': [None, 10, 20, 30],\n",
    "            'classifier__min_samples_split': [2, 5, 10],\n",
    "            'classifier__class_weight': ['balanced', 'balanced_subsample', None]\n",
    "        },\n",
    "        \n",
    "        'Gradient Boosting': {\n",
    "            'classifier__n_estimators': [50, 100, 200],\n",
    "            'classifier__learning_rate': [0.01, 0.1, 0.2],\n",
    "            'classifier__max_depth': [3, 5, 7],\n",
    "            'classifier__subsample': [0.8, 1.0]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Define the model pipeline\n",
    "    if best_model_name == 'Logistic Regression':\n",
    "        model = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', LogisticRegression(max_iter=1000))\n",
    "        ])\n",
    "    elif best_model_name == 'Random Forest':\n",
    "        model = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', RandomForestClassifier(random_state=42))\n",
    "        ])\n",
    "    elif best_model_name == 'Gradient Boosting':\n",
    "        model = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', GradientBoostingClassifier(random_state=42))\n",
    "        ])\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model name: {best_model_name}\")\n",
    "    \n",
    "    # Create grid search\n",
    "    grid_search = GridSearchCV(\n",
    "        model,\n",
    "        param_grids[best_model_name],\n",
    "        cv=5,\n",
    "        scoring='f1',\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Fit grid search\n",
    "    print(f\"Tuning {best_model_name}...\")\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Print best parameters\n",
    "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Best cross-validation score: {grid_search.best_score_:.4f}\")\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    print(\"\\nTest set performance:\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"F1 Score: {f1_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    return grid_search.best_params_, best_model, X_test, y_test\n",
    "\n",
    "def generate_decision_rules(model, feature_names, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Generate interpretable decision rules from a logistic regression model.\n",
    "    \n",
    "    Parameters:\n",
    "    model: Trained logistic regression model\n",
    "    feature_names: List of feature names\n",
    "    threshold: Decision threshold\n",
    "    \n",
    "    Returns:\n",
    "    str: Decision rules\n",
    "    \"\"\"\n",
    "    if not hasattr(model, 'coef_'):\n",
    "        return \"Model does not support coefficient extraction.\"\n",
    "    \n",
    "    # Extract coefficients\n",
    "    coefficients = model.coef_[0]\n",
    "    intercept = model.intercept_[0]\n",
    "    \n",
    "    # Sort features by absolute coefficient value\n",
    "    sorted_indices = np.argsort(np.abs(coefficients))[::-1]\n",
    "    sorted_features = [feature_names[i] for i in sorted_indices]\n",
    "    sorted_coefficients = coefficients[sorted_indices]\n",
    "    \n",
    "    # Generate rules\n",
    "    rules = []\n",
    "    \n",
    "    rules.append(f\"Prediction formula: log-odds = {intercept:.4f}\")\n",
    "    \n",
    "    for feature, coef in zip(sorted_features, sorted_coefficients):\n",
    "        if coef > 0:\n",
    "            rules.append(f\"  + {coef:.4f} × {feature}\")\n",
    "        else:\n",
    "            rules.append(f\"  - {abs(coef):.4f} × {feature}\")\n",
    "    \n",
    "    rules.append(f\"\\nDecision rule: Driver will start driving if log-odds > {np.log(threshold/(1-threshold)):.4f}\")\n",
    "    \n",
    "    # Generate simplified rules for top features\n",
    "    simplified_rules = [\"\\nSimplified rules:\"]\n",
    "    \n",
    "    top_positive = [(feature, coef) for feature, coef in zip(sorted_features, sorted_coefficients) if coef > 0][:3]\n",
    "    top_negative = [(feature, coef) for feature, coef in zip(sorted_features, sorted_coefficients) if coef < 0][:3]\n",
    "    \n",
    "    simplified_rules.append(\"Factors that increase likelihood of driving:\")\n",
    "    for feature, coef in top_positive:\n",
    "        simplified_rules.append(f\"  - {feature} (weight: +{coef:.4f})\")\n",
    "    \n",
    "    simplified_rules.append(\"\\nFactors that decrease likelihood of driving:\")\n",
    "    for feature, coef in top_negative:\n",
    "        simplified_rules.append(f\"  - {feature} (weight: {coef:.4f})\")\n",
    "    \n",
    "    return \"\\n\".join(rules + simplified_rules)\n",
    "\n",
    "def main(file_path):\n",
    "    \"\"\"\n",
    "    Main function to run the predictive modeling pipeline.\n",
    "    \n",
    "    Parameters:\n",
    "    file_path (str): Path to the CSV file\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    print(\"Loading and preparing data...\")\n",
    "    X, y, feature_names = load_and_prepare_data(file_path)\n",
    "    \n",
    "    print(\"\\nBuilding and evaluating models...\")\n",
    "    results, X_test, y_test = build_and_evaluate_models(X, y, feature_names)\n",
    "    \n",
    "    print(\"\\nVisualizing model results...\")\n",
    "    visualize_model_results(results, X_test, y_test)\n",
    "    \n",
    "    # Find the best model based on F1 score\n",
    "    best_model_name = max([(name, result['f1']) for name, result in results.items() \n",
    "                         if name not in ['feature_importance', 'rf_importance']], \n",
    "                        key=lambda x: x[1])[0]\n",
    "    \n",
    "    print(f\"\\nBest model: {best_model_name} (F1: {results[best_model_name]['f1']:.4f})\")\n",
    "    \n",
    "    print(\"\\nTuning the best model...\")\n",
    "    best_params, tuned_model, X_test, y_test = tune_best_model(X, y, best_model_name)\n",
    "    \n",
    "    # Extract and display decision rules if logistic regression\n",
    "    if best_model_name == 'Logistic Regression':\n",
    "        # Get the feature names after preprocessing\n",
    "        preprocessor = tuned_model.named_steps['preprocessor']\n",
    "        classifier = tuned_model.named_steps['classifier']\n",
    "        \n",
    "        try:\n",
    "            cat_features = preprocessor.transformers_[1][1].named_steps['onehot'].get_feature_names_out(\n",
    "                [col for col in X.columns if X[col].dtype == 'object'])\n",
    "            \n",
    "            all_features = list(cat_features) + [col for col in X.columns if X[col].dtype != 'object']\n",
    "            \n",
    "            print(\"\\nDecision Rules:\")\n",
    "            rules = generate_decision_rules(classifier, all_features)\n",
    "            print(rules)\n",
    "            \n",
    "            # Save rules to file\n",
    "            with open('uber_driver_decision_rules.txt', 'w') as f:\n",
    "                f.write(rules)\n",
    "        except:\n",
    "            print(\"Could not extract decision rules.\")\n",
    "    \n",
    "    print(\"\\nAnalysis complete. Visualizations saved to files.\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    main('data1.csv')  # Replace with your file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All confusion matrix visualizations saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Set style for better visualizations\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"viridis\")\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = ['Arial']\n",
    "plt.rcParams['figure.figsize'] = (14, 12)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "# Confusion matrices for each model\n",
    "confusion_matrices = {\n",
    "    'Logistic Regression': np.array([[8276, 1428], [49, 1184]]),\n",
    "    'Random Forest': np.array([[8722, 982], [220, 1013]]),\n",
    "    'Gradient Boosting': np.array([[9398, 306], [489, 744]]),\n",
    "    'Tuned Gradient Boosting': np.array([[9361, 343], [430, 803]])\n",
    "}\n",
    "\n",
    "def create_enhanced_confusion_matrix(model_name, cm):\n",
    "    \"\"\"\n",
    "    Create an enhanced, visually appealing confusion matrix visualization\n",
    "    with business context and explanations.\n",
    "    \n",
    "    Parameters:\n",
    "    model_name (str): Name of the model\n",
    "    cm (numpy.ndarray): Confusion matrix values\n",
    "    \"\"\"\n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    \n",
    "    # Calculate percentages and totals\n",
    "    total = cm.sum()\n",
    "    tn, fp = cm[0]\n",
    "    fn, tp = cm[1]\n",
    "    \n",
    "    # Calculate overall metrics\n",
    "    accuracy = (tp + tn) / total\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    # Create a custom colormap (blue to green gradient)\n",
    "    colors = ['#f0f9ff', '#c6e2ff', '#93c4ff', '#5da7f5', '#1976D2']\n",
    "    cmap = LinearSegmentedColormap.from_list('blue_gradient', colors)\n",
    "    \n",
    "    # Create a normalized confusion matrix for coloring\n",
    "    norm_cm = cm / total\n",
    "    \n",
    "    # Create the heatmap without annotations first\n",
    "    sns.heatmap(cm, annot=False, cmap=cmap, cbar=False, ax=ax)\n",
    "    \n",
    "    # Add text manually with enhanced formatting\n",
    "    fontsize_value = 16\n",
    "    fontsize_pct = 14\n",
    "    fontsize_label = 12\n",
    "    \n",
    "    # Add count and percentage for each cell\n",
    "    labels = [['True Negative (TN)', 'False Positive (FP)'], \n",
    "              ['False Negative (FN)', 'True Positive (TP)']]\n",
    "    \n",
    "    explanations = [\n",
    "        [\n",
    "            \"Driver correctly predicted\\nNOT to take first trip\",\n",
    "            \"Driver predicted to take\\nfirst trip but did NOT\"\n",
    "        ],\n",
    "        [\n",
    "            \"Driver predicted NOT to take\\nfirst trip but DID take it\",\n",
    "            \"Driver correctly predicted\\nto take first trip\"\n",
    "        ]\n",
    "    ]\n",
    "    \n",
    "    business_impact = [\n",
    "        [\n",
    "            \"Correctly identified non-converters\\nCan safely exclude from interventions\",\n",
    "            \"Wasted resources on interventions\\nfor drivers who wouldn't convert\"\n",
    "        ],\n",
    "        [\n",
    "            \"Missed opportunity to convert\\nthese drivers with interventions\",\n",
    "            \"Correctly targeted drivers\\nwho will convert\"\n",
    "        ]\n",
    "    ]\n",
    "    \n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            # Calculate percentage of total\n",
    "            val = cm[i, j]\n",
    "            pct = val / total * 100\n",
    "            \n",
    "            # Position text in the middle of the cell\n",
    "            y, x = i + 0.5, j + 0.5\n",
    "            \n",
    "            # Add cell label\n",
    "            ax.text(x, y - 0.30, labels[i][j], ha='center', va='center', \n",
    "                   fontsize=fontsize_label, fontweight='bold', \n",
    "                   color='black' if norm_cm[i, j] < 0.5 else 'white')\n",
    "            \n",
    "            # Add count value\n",
    "            ax.text(x, y, f\"{val:,}\", ha='center', va='center', \n",
    "                   fontsize=fontsize_value, fontweight='bold', \n",
    "                   color='black' if norm_cm[i, j] < 0.5 else 'white')\n",
    "            \n",
    "            # Add percentage\n",
    "            ax.text(x, y + 0.24, f\"({pct:.1f}%)\", ha='center', va='center', \n",
    "                   fontsize=fontsize_pct, \n",
    "                   color='black' if norm_cm[i, j] < 0.5 else 'white')\n",
    "            \n",
    "            # Add explanation\n",
    "            ax.text(x, y + 0.42, explanations[i][j], ha='center', va='center', \n",
    "                   fontsize=10, style='italic', \n",
    "                   color='black' if norm_cm[i, j] < 0.4 else 'white')\n",
    "    \n",
    "    # Set axis labels and title\n",
    "    ax.set_xlabel('Predicted Label', fontsize=14, fontweight='bold')\n",
    "    ax.set_ylabel('Actual Label', fontsize=14, fontweight='bold')\n",
    "    plt.title(f'Confusion Matrix: {model_name}', fontsize=18, fontweight='bold', pad=20)\n",
    "    \n",
    "    # Set custom tick labels\n",
    "    ax.set_xticklabels(['Did Not Convert', 'Converted'], fontsize=12)\n",
    "    ax.set_yticklabels(['Did Not Convert', 'Converted'], fontsize=12)\n",
    "    \n",
    "    # Add a summary box with metrics\n",
    "    metrics_box = (\n",
    "        f\"Model Performance Metrics:\\n\"\n",
    "        f\"Accuracy: {accuracy:.1%}\\n\"\n",
    "        f\"Precision: {precision:.1%}\\n\"\n",
    "        f\"Recall: {recall:.1%}\\n\"\n",
    "        f\"F1 Score: {f1:.1%}\\n\\n\"\n",
    "        f\"Total Drivers: {total:,}\"\n",
    "    )\n",
    "    \n",
    "    # Add metrics box\n",
    "    plt.figtext(0.92, 0.5, metrics_box, \n",
    "               bbox=dict(facecolor='#f0f0f0', alpha=0.9, boxstyle='round,pad=0.5', \n",
    "                        edgecolor='#cccccc'),\n",
    "               fontsize=12, ha='center')\n",
    "    \n",
    "    # Add business implications section under the matrix\n",
    "    implications = (\n",
    "        \"Business Implications:\\n\"\n",
    "        f\"• {tp:,} drivers ({tp/total:.1%}) were correctly identified as converters (True Positives)\\n\"\n",
    "        f\"• {tn:,} drivers ({tn/total:.1%}) were correctly identified as non-converters (True Negatives)\\n\"\n",
    "        f\"• {fp:,} drivers ({fp/total:.1%}) received unnecessary interventions (False Positives)\\n\"\n",
    "        f\"• {fn:,} drivers ({fn/total:.1%}) were missed opportunities for conversion (False Negatives)\"\n",
    "    )\n",
    "    \n",
    "    plt.figtext(0.5, 0.08, implications, ha='center', fontsize=12,\n",
    "              bbox=dict(facecolor='#eaf2f8', alpha=0.9, boxstyle='round,pad=0.5',\n",
    "                       edgecolor='#a9cce3'))\n",
    "    \n",
    "    # Add a title for quadrant explanations\n",
    "    plt.figtext(0.5, 0.15, \"What Each Quadrant Means for Uber's Driver Conversion\", \n",
    "              ha='center', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0.2, 0.85, 0.95])  # Adjust layout to make room for annotations\n",
    "    \n",
    "    # Save the figure\n",
    "    plt.savefig(f'uber_confusion_matrix_{model_name.replace(\" \", \"_\").lower()}.png', \n",
    "               dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def create_comparison_of_confusion_matrices():\n",
    "    \"\"\"Create a 2x2 grid comparing confusion matrices for all models.\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(20, 16))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    class_names = ['Did Not Convert', 'Converted']\n",
    "    \n",
    "    # Create a custom colormap (blue to green gradient)\n",
    "    colors = ['#f0f9ff', '#c6e2ff', '#93c4ff', '#5da7f5', '#1976D2']\n",
    "    cmap = LinearSegmentedColormap.from_list('blue_gradient', colors)\n",
    "    \n",
    "    for i, (model_name, cm) in enumerate(confusion_matrices.items()):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        # Calculate metrics\n",
    "        total = cm.sum()\n",
    "        tn, fp = cm[0]\n",
    "        fn, tp = cm[1]\n",
    "        \n",
    "        accuracy = (tp + tn) / total\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        # Create the heatmap\n",
    "        sns.heatmap(cm, annot=True, fmt=',d', cmap=cmap, cbar=False, ax=ax)\n",
    "        \n",
    "        # Set labels\n",
    "        ax.set_xlabel('Predicted Label', fontsize=12)\n",
    "        ax.set_ylabel('Actual Label', fontsize=12)\n",
    "        ax.set_title(f'{model_name}', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        # Set tick labels\n",
    "        ax.set_xticklabels(class_names, fontsize=10)\n",
    "        ax.set_yticklabels(class_names, fontsize=10)\n",
    "        \n",
    "        # Add metrics\n",
    "        metrics_text = (\n",
    "            f\"Accuracy: {accuracy:.1%}\\n\"\n",
    "            f\"Precision: {precision:.1%}\\n\"\n",
    "            f\"Recall: {recall:.1%}\\n\"\n",
    "            f\"F1 Score: {f1:.1%}\"\n",
    "        )\n",
    "        \n",
    "        ax.text(1.5, 1.5, metrics_text, ha='center', va='center', \n",
    "               bbox=dict(facecolor='white', alpha=0.8, boxstyle='round,pad=0.3'),\n",
    "               fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('Confusion Matrix Comparison Across Models', fontsize=18, fontweight='bold', y=1.02)\n",
    "    plt.savefig('uber_confusion_matrix_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def create_business_impact_viz(model_name='Tuned Gradient Boosting'):\n",
    "    \"\"\"Create a visualization focusing on the business impact of model predictions.\"\"\"\n",
    "    # Get confusion matrix for the specified model\n",
    "    cm = confusion_matrices[model_name]\n",
    "    tn, fp = cm[0]\n",
    "    fn, tp = cm[1]\n",
    "    total = cm.sum()\n",
    "    \n",
    "    # Calculate key metrics\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    \n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=(14, 10))\n",
    "    \n",
    "    # Define the quadrants\n",
    "    width, height = 10, 10\n",
    "    \n",
    "    # Create the quadrants\n",
    "    quadrants = [\n",
    "        patches.Rectangle((0, 0), width/2, height/2, linewidth=1, edgecolor='black', facecolor='#c8e6c9'),  # TN\n",
    "        patches.Rectangle((width/2, 0), width/2, height/2, linewidth=1, edgecolor='black', facecolor='#ffcdd2'),  # FP\n",
    "        patches.Rectangle((0, height/2), width/2, height/2, linewidth=1, edgecolor='black', facecolor='#ffecb3'),  # FN\n",
    "        patches.Rectangle((width/2, height/2), width/2, height/2, linewidth=1, edgecolor='black', facecolor='#bbdefb')  # TP\n",
    "    ]\n",
    "    \n",
    "    # Add the quadrants to the plot\n",
    "    for quadrant in quadrants:\n",
    "        ax.add_patch(quadrant)\n",
    "    \n",
    "    # Calculate percentages and counts\n",
    "    tn_pct = tn / total * 100\n",
    "    fp_pct = fp / total * 100\n",
    "    fn_pct = fn / total * 100\n",
    "    tp_pct = tp / total * 100\n",
    "    \n",
    "    # Add quadrant labels and statistics\n",
    "    quadrant_info = [\n",
    "        {\n",
    "            'position': (width/4, height/4),\n",
    "            'title': 'True Negatives',\n",
    "            'count': tn,\n",
    "            'percent': tn_pct,\n",
    "            'description': 'Drivers correctly predicted\\nNOT to take first trip',\n",
    "            'business_impact': 'No action needed - these drivers\\nwould not convert anyway'\n",
    "        },\n",
    "        {\n",
    "            'position': (width*3/4, height/4),\n",
    "            'title': 'False Positives',\n",
    "            'count': fp,\n",
    "            'percent': fp_pct,\n",
    "            'description': 'Drivers predicted to take\\nfirst trip but did NOT',\n",
    "            'business_impact': 'Resources wasted on\\nunnecessary interventions'\n",
    "        },\n",
    "        {\n",
    "            'position': (width/4, height*3/4),\n",
    "            'title': 'False Negatives',\n",
    "            'count': fn,\n",
    "            'percent': fn_pct,\n",
    "            'description': 'Drivers predicted NOT to take\\nfirst trip but DID take it',\n",
    "            'business_impact': 'Missed opportunity to help\\nthese drivers convert faster'\n",
    "        },\n",
    "        {\n",
    "            'position': (width*3/4, height*3/4),\n",
    "            'title': 'True Positives',\n",
    "            'count': tp,\n",
    "            'percent': tp_pct,\n",
    "            'description': 'Drivers correctly predicted\\nto take first trip',\n",
    "            'business_impact': 'Correctly targeted\\nfor conversion support'\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Add the information to each quadrant\n",
    "    for info in quadrant_info:\n",
    "        x, y = info['position']\n",
    "        \n",
    "        # Add title\n",
    "        ax.text(x, y+1.5, info['title'], ha='center', va='center', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        # Add count and percentage\n",
    "        ax.text(x, y+0.5, f\"{info['count']:,} drivers ({info['percent']:.1f}%)\", \n",
    "                ha='center', va='center', fontsize=12)\n",
    "        \n",
    "        # Add description\n",
    "        ax.text(x, y-0.5, info['description'], ha='center', va='center', fontsize=10, style='italic')\n",
    "        \n",
    "        # Add business impact\n",
    "        ax.text(x, y-1.5, info['business_impact'], ha='center', va='center', fontsize=10, \n",
    "                bbox=dict(facecolor='white', alpha=0.7, boxstyle='round,pad=0.2'))\n",
    "    \n",
    "    # Add axis labels\n",
    "    ax.text(width/4, -0.7, 'Predicted: Will NOT Convert', ha='center', va='center', fontsize=12)\n",
    "    ax.text(width*3/4, -0.7, 'Predicted: Will Convert', ha='center', va='center', fontsize=12)\n",
    "    ax.text(-0.7, height/4, 'Actual: Did NOT Convert', ha='center', va='center', fontsize=12, rotation=90)\n",
    "    ax.text(-0.7, height*3/4, 'Actual: Did Convert', ha='center', va='center', fontsize=12, rotation=90)\n",
    "    \n",
    "    # Set plot limits\n",
    "    ax.set_xlim(-2, width+2)\n",
    "    ax.set_ylim(-2, height+2)\n",
    "    \n",
    "    # Remove axes\n",
    "    ax.set_axis_off()\n",
    "    \n",
    "    # Add title\n",
    "    plt.suptitle(f'Business Impact of {model_name} Predictions', fontsize=16, fontweight='bold', y=0.98)\n",
    "    \n",
    "    # Add subtitle with precision and recall explanation\n",
    "    subtitle = (\n",
    "        f\"Precision: {precision:.1%} of drivers predicted to convert actually did (TP / (TP + FP))\\n\"\n",
    "        f\"Recall: {recall:.1%} of drivers who actually converted were predicted correctly (TP / (TP + FN))\"\n",
    "    )\n",
    "    plt.title(subtitle, fontsize=12, pad=20)\n",
    "    \n",
    "    # Add ROI information\n",
    "    roi_text = (\n",
    "        \"Potential Business Impact:\\n\\n\"\n",
    "        f\"• By correctly identifying {tp:,} converters, Uber can provide targeted support to its most promising drivers\\n\"\n",
    "        f\"• By avoiding {tn:,} likely non-converters, Uber can save resources and focus efforts efficiently\\n\"\n",
    "        f\"• The {fn:,} missed converters represent an opportunity to improve the model and capture more drivers\\n\"\n",
    "        f\"• The {fp:,} false positives represent wasted resources that could be better allocated\"\n",
    "    )\n",
    "    \n",
    "    plt.figtext(0.5, 0.05, roi_text, ha='center', fontsize=12,\n",
    "               bbox=dict(facecolor='#eaf2f8', alpha=0.9, boxstyle='round,pad=0.5',\n",
    "                         edgecolor='#a9cce3', linewidth=2))\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0.12, 1, 0.92])\n",
    "    plt.savefig(f'uber_confusion_matrix_business_impact.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# Create all visualizations\n",
    "if __name__ == \"__main__\":\n",
    "    # Create enhanced confusion matrix for each model\n",
    "    for model_name, cm in confusion_matrices.items():\n",
    "        create_enhanced_confusion_matrix(model_name, cm)\n",
    "    \n",
    "    # Create comparison visualization\n",
    "    create_comparison_of_confusion_matrices()\n",
    "    \n",
    "    # Create business impact visualization\n",
    "    create_business_impact_viz()\n",
    "    \n",
    "    print(\"All confusion matrix visualizations saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All visualizations saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "# Set style for better visualizations\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"viridis\")\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = ['Arial']\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "# Create data for missing values\n",
    "missing_data = {\n",
    "    'column': ['signup_os', 'bgc_date', 'vehicle_added_date', 'vehicle_make', 'vehicle_model', 'vehicle_year', 'first_completed_date'],\n",
    "    'missing_count': [6857, 21785, 41547, 41458, 41458, 41458, 48544],\n",
    "    'total': [54681] * 7\n",
    "}\n",
    "\n",
    "# Create conversion rate data\n",
    "conversion_data = {\n",
    "    'bgc_completed': {'Yes': 18.66, 'No': 0.00},\n",
    "    'vehicle_added': {'Yes': 44.71, 'No': 0.64},\n",
    "    'signup_channel': {'Organic': 9.01, 'Paid': 6.19, 'Referral': 19.89},\n",
    "    'funnel_completion': {\n",
    "        'BGC Only': 1.32,\n",
    "        'BGC and Vehicle': 45.59,\n",
    "        'No BGC, No Vehicle': 0.00,\n",
    "        'Vehicle Only': 0.00\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create feature importance data\n",
    "feature_importance = {\n",
    "    'Feature': ['bgc_completed', 'has_vehicle_info', 'vehicle_added', \n",
    "                'signup_channel_Referral', 'signup_channel_Paid', 'signup_channel_Organic',\n",
    "                'city_name_Berton', 'city_name_Strark', 'city_name_Wrouver'],\n",
    "    'Importance': [4.493994, 2.191576, 1.847814, 0.305712, 0.210220, 0.095577, \n",
    "                  0.065396, 0.054656, 0.010825]\n",
    "}\n",
    "\n",
    "# Model performance data\n",
    "model_performance = {\n",
    "    'Accuracy': 0.8933,\n",
    "    'Precision': 0.5258,\n",
    "    'Recall': 0.5450,\n",
    "    'F1 Score': 0.5352\n",
    "}\n",
    "\n",
    "# Confusion matrix data\n",
    "confusion_matrix = np.array([[9098, 606], [561, 672]])\n",
    "\n",
    "def create_missing_data_visualization():\n",
    "    \"\"\"Create a visualization of missing data.\"\"\"\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(missing_data)\n",
    "    df['missing_percentage'] = df['missing_count'] / df['total'] * 100\n",
    "    \n",
    "    # Sort by missing percentage\n",
    "    df = df.sort_values('missing_percentage', ascending=False)\n",
    "    \n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    # Create bars\n",
    "    bars = ax.barh(df['column'], df['missing_percentage'], color=sns.color_palette(\"viridis\", len(df)))\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, bar in enumerate(bars):\n",
    "        count = df.iloc[i]['missing_count']\n",
    "        pct = df.iloc[i]['missing_percentage']\n",
    "        ax.text(pct + 1, i, f\"{int(count):,} ({pct:.1f}%)\", \n",
    "                va='center', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    # Customize plot\n",
    "    ax.set_xlabel('Percentage of Missing Values', fontsize=12)\n",
    "    ax.set_ylabel('Column', fontsize=12)\n",
    "    ax.set_title('Missing Data in Uber Driver Dataset', fontsize=16, fontweight='bold')\n",
    "    ax.set_xlim(0, 100)\n",
    "    ax.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Add a vertical line at 50%\n",
    "    ax.axvline(x=50, color='red', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Add annotations for missing data patterns\n",
    "    high_missing = df[df['missing_percentage'] > 75]['column'].tolist()\n",
    "    if high_missing:\n",
    "        high_missing_text = \", \".join(high_missing)\n",
    "        plt.figtext(0.5, 0.01, f\"Columns with >75% missing data: {high_missing_text}\\nMost of these represent conversion steps most drivers don't complete\",\n",
    "                   ha=\"center\", fontsize=10, bbox={\"facecolor\":\"orange\", \"alpha\":0.2, \"pad\":5})\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0.05, 1, 0.98])\n",
    "    plt.savefig('uber_driver_missing_data.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def create_conversion_rate_visualization():\n",
    "    \"\"\"Create visualizations for conversion rates by different factors.\"\"\"\n",
    "    # Create figure with subplots\n",
    "    fig = plt.figure(figsize=(16, 12))\n",
    "    gs = gridspec.GridSpec(2, 2, figure=fig)\n",
    "    \n",
    "    # 1. BGC Completion\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    bgc_labels = list(conversion_data['bgc_completed'].keys())\n",
    "    bgc_values = list(conversion_data['bgc_completed'].values())\n",
    "    \n",
    "    bars1 = ax1.bar(bgc_labels, bgc_values, color=['#1976D2', '#64B5F6'])\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar in bars1:\n",
    "        height = bar.get_height()\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                f\"{height:.2f}%\", ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    ax1.set_ylim(0, 100)\n",
    "    ax1.set_title('Conversion Rate by Background Check Status', fontsize=14, fontweight='bold')\n",
    "    ax1.set_ylabel('Conversion Rate (%)', fontsize=12)\n",
    "    ax1.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Add annotation\n",
    "    ax1.text(0.5, 50, \"No drivers without\\nBGC convert\", \n",
    "             ha='center', va='center', fontsize=12, \n",
    "             bbox=dict(facecolor='red', alpha=0.1, boxstyle='round,pad=0.5'))\n",
    "    \n",
    "    # 2. Vehicle Addition\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    vehicle_labels = list(conversion_data['vehicle_added'].keys())\n",
    "    vehicle_values = list(conversion_data['vehicle_added'].values())\n",
    "    \n",
    "    bars2 = ax2.bar(vehicle_labels, vehicle_values, color=['#388E3C', '#81C784'])\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar in bars2:\n",
    "        height = bar.get_height()\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                f\"{height:.2f}%\", ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    ax2.set_ylim(0, 50)\n",
    "    ax2.set_title('Conversion Rate by Vehicle Addition Status', fontsize=14, fontweight='bold')\n",
    "    ax2.set_ylabel('Conversion Rate (%)', fontsize=12)\n",
    "    ax2.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Add annotation\n",
    "    ax2.text(1, 35, \"70x higher conversion\\nwith vehicle added\", \n",
    "             ha='center', va='center', fontsize=12, \n",
    "             bbox=dict(facecolor='green', alpha=0.1, boxstyle='round,pad=0.5'))\n",
    "    \n",
    "    # 3. Signup Channel\n",
    "    ax3 = fig.add_subplot(gs[1, 0])\n",
    "    channel_labels = list(conversion_data['signup_channel'].keys())\n",
    "    channel_values = list(conversion_data['signup_channel'].values())\n",
    "    \n",
    "    # Sort by conversion rate\n",
    "    sorted_indices = np.argsort(channel_values)[::-1]\n",
    "    channel_labels = [channel_labels[i] for i in sorted_indices]\n",
    "    channel_values = [channel_values[i] for i in sorted_indices]\n",
    "    \n",
    "    colors = ['#7B1FA2', '#9C27B0', '#BA68C8']\n",
    "    bars3 = ax3.bar(channel_labels, channel_values, color=colors)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar in bars3:\n",
    "        height = bar.get_height()\n",
    "        ax3.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "                f\"{height:.2f}%\", ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    ax3.set_ylim(0, 25)\n",
    "    ax3.set_title('Conversion Rate by Signup Channel', fontsize=14, fontweight='bold')\n",
    "    ax3.set_ylabel('Conversion Rate (%)', fontsize=12)\n",
    "    ax3.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Add annotation\n",
    "    ax3.text(0, 20, \"Referrals convert at 3x\\nthe rate of paid channels\", \n",
    "             ha='center', va='center', fontsize=12, \n",
    "             bbox=dict(facecolor='purple', alpha=0.1, boxstyle='round,pad=0.5'))\n",
    "    \n",
    "    # 4. Funnel Completion\n",
    "    ax4 = fig.add_subplot(gs[1, 1])\n",
    "    funnel_labels = list(conversion_data['funnel_completion'].keys())\n",
    "    funnel_values = list(conversion_data['funnel_completion'].values())\n",
    "    \n",
    "    # Sort by conversion rate\n",
    "    sorted_indices = np.argsort(funnel_values)[::-1]\n",
    "    funnel_labels = [funnel_labels[i] for i in sorted_indices]\n",
    "    funnel_values = [funnel_values[i] for i in sorted_indices]\n",
    "    \n",
    "    colors = ['#E65100', '#FB8C00', '#FFB74D', '#FFE0B2']\n",
    "    bars4 = ax4.bar(funnel_labels, funnel_values, color=colors)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar in bars4:\n",
    "        height = bar.get_height()\n",
    "        ax4.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                f\"{height:.2f}%\", ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    ax4.set_ylim(0, 50)\n",
    "    ax4.set_title('Conversion Rate by Funnel Completion', fontsize=14, fontweight='bold')\n",
    "    ax4.set_ylabel('Conversion Rate (%)', fontsize=12)\n",
    "    ax4.set_xticklabels(funnel_labels, rotation=45, ha='right')\n",
    "    ax4.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Add annotation\n",
    "    ax4.text(0, 40, \"Both steps are critical\\nfor conversion\", \n",
    "             ha='center', va='center', fontsize=12, \n",
    "             bbox=dict(facecolor='orange', alpha=0.1, boxstyle='round,pad=0.5'))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('Uber Driver Conversion Rates by Different Factors', fontsize=18, fontweight='bold', y=1.02)\n",
    "    plt.savefig('uber_driver_conversion_rates.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def create_feature_importance_visualization():\n",
    "    \"\"\"Create a visualization of feature importance.\"\"\"\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(feature_importance)\n",
    "    df = df.sort_values('Importance', ascending=True)\n",
    "    \n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    # Create bars with a color gradient\n",
    "    colors = plt.cm.viridis(np.linspace(0.1, 0.9, len(df)))\n",
    "    bars = ax.barh(df['Feature'], df['Importance'], color=colors)\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, bar in enumerate(bars):\n",
    "        width = bar.get_width()\n",
    "        ax.text(width + 0.1, i, f\"{width:.2f}\", va='center', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    # Customize plot\n",
    "    ax.set_xlabel('Importance Score', fontsize=12)\n",
    "    ax.set_ylabel('Feature', fontsize=12)\n",
    "    ax.set_title('Feature Importance in Driver Conversion Prediction', fontsize=16, fontweight='bold')\n",
    "    ax.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Add annotations for feature groups\n",
    "    plt.figtext(0.5, 0.01, \n",
    "               \"Key Insights:\\n\"\n",
    "               \"• Completing onboarding steps (BGC, vehicle) are by far the strongest predictors\\n\"\n",
    "               \"• Referral channel is the most important acquisition source\\n\"\n",
    "               \"• City has minimal impact on conversion likelihood\",\n",
    "               ha=\"center\", fontsize=12, bbox={\"facecolor\":\"lightblue\", \"alpha\":0.2, \"pad\":5})\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0.07, 1, 0.98])\n",
    "    plt.savefig('uber_driver_feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def create_model_performance_visualization():\n",
    "    \"\"\"Create visualizations for model performance.\"\"\"\n",
    "    # Create figure with subplots\n",
    "    fig = plt.figure(figsize=(16, 8))\n",
    "    gs = gridspec.GridSpec(1, 2, figure=fig, width_ratios=[1, 2])\n",
    "    \n",
    "    # 1. Performance Metrics\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    \n",
    "    metrics = list(model_performance.keys())\n",
    "    values = list(model_performance.values())\n",
    "    \n",
    "    # Create bars with a color gradient\n",
    "    colors = plt.cm.viridis(np.linspace(0.2, 0.8, len(metrics)))\n",
    "    bars = ax1.bar(metrics, values, color=colors)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                f\"{height:.2f}\", ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    ax1.set_ylim(0, 1)\n",
    "    ax1.set_title('Model Performance Metrics', fontsize=14, fontweight='bold')\n",
    "    ax1.set_ylabel('Score', fontsize=12)\n",
    "    ax1.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # 2. Confusion Matrix\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    \n",
    "    # Create a normalized confusion matrix\n",
    "    cm_norm = confusion_matrix / confusion_matrix.sum()\n",
    "    \n",
    "    # Create a custom colormap (blue gradient)\n",
    "    colors = ['#f0f9ff', '#c6e2ff', '#93c4ff', '#5da7f5', '#1976D2']\n",
    "    cmap = LinearSegmentedColormap.from_list('blue_gradient', colors)\n",
    "    \n",
    "    # Create the heatmap\n",
    "    sns.heatmap(confusion_matrix, annot=True, fmt=',d', cmap=cmap, cbar=False, ax=ax2)\n",
    "    \n",
    "    # Add percentage annotations\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            ax2.text(j + 0.5, i + 0.7, f\"({cm_norm[i, j]*100:.1f}%)\", \n",
    "                    ha='center', va='center', fontsize=10)\n",
    "    \n",
    "    # Set labels\n",
    "    ax2.set_xlabel('Predicted Label', fontsize=12)\n",
    "    ax2.set_ylabel('Actual Label', fontsize=12)\n",
    "    ax2.set_title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Set tick labels\n",
    "    ax2.set_xticklabels(['Did Not Convert', 'Converted'], fontsize=10)\n",
    "    ax2.set_yticklabels(['Did Not Convert', 'Converted'], fontsize=10)\n",
    "    \n",
    "    # Add explanatory labels for quadrants\n",
    "    ax2.text(0.5, 0.3, \"True Negatives\", ha='center', va='center', fontsize=9, \n",
    "             color='black', weight='bold')\n",
    "    ax2.text(1.5, 0.3, \"False Positives\", ha='center', va='center', fontsize=9, \n",
    "             color='black', weight='bold')\n",
    "    ax2.text(0.5, 1.3, \"False Negatives\", ha='center', va='center', fontsize=9, \n",
    "             color='black', weight='bold')\n",
    "    ax2.text(1.5, 1.3, \"True Positives\", ha='center', va='center', fontsize=9, \n",
    "             color='black', weight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('Uber Driver Conversion Model Performance', fontsize=18, fontweight='bold', y=1.02)\n",
    "    plt.savefig('uber_driver_model_performance.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def create_funnel_visualization():\n",
    "    \"\"\"Create a conversion funnel visualization.\"\"\"\n",
    "    total_drivers = 54681\n",
    "    drivers_with_bgc = 32896\n",
    "    drivers_with_vehicle = 13134\n",
    "    drivers_with_both = 12879\n",
    "    converted_drivers = 6137\n",
    "    \n",
    "    # Calculate percentages\n",
    "    bgc_pct = drivers_with_bgc / total_drivers * 100\n",
    "    vehicle_pct = drivers_with_vehicle / total_drivers * 100\n",
    "    both_pct = drivers_with_both / total_drivers * 100\n",
    "    converted_pct = converted_drivers / total_drivers * 100\n",
    "    \n",
    "    # Calculate conversion rate for drivers with both BGC and vehicle\n",
    "    both_to_converted_pct = converted_drivers / drivers_with_both * 100\n",
    "    \n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    # Define the stages\n",
    "    stages = ['Total Signups', 'BGC Completed', 'Vehicle Added', 'Both Steps Completed', 'First Trip Completed']\n",
    "    values = [total_drivers, drivers_with_bgc, drivers_with_vehicle, drivers_with_both, converted_drivers]\n",
    "    percentages = [100, bgc_pct, vehicle_pct, both_pct, converted_pct]\n",
    "    \n",
    "    # Create a gradient of colors\n",
    "    colors = plt.cm.viridis(np.linspace(0.8, 0.3, len(stages)))\n",
    "    \n",
    "    # Create bars\n",
    "    y_pos = np.arange(len(stages))\n",
    "    bars = ax.barh(y_pos, percentages, color=colors)\n",
    "    \n",
    "    # Add stage labels and values\n",
    "    for i, (bar, value, pct) in enumerate(zip(bars, values, percentages)):\n",
    "        # Add stage label\n",
    "        ax.text(-5, i, stages[i], ha='right', va='center', fontsize=12, fontweight='bold')\n",
    "        \n",
    "        # Add count and percentage inside the bar\n",
    "        ax.text(5, i, f\"{value:,} ({pct:.1f}%)\", va='center', fontsize=10, \n",
    "                color='white' if i > 0 else 'black')\n",
    "    \n",
    "    # Customize the plot\n",
    "    ax.set_xlim(0, 105)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlabel('Percentage of Initial Signups', fontsize=12)\n",
    "    ax.set_title('Driver Conversion Funnel', fontsize=16, fontweight='bold')\n",
    "    ax.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Add conversion rate annotation\n",
    "    plt.figtext(0.5, 0.05, \n",
    "               f\"Key Insight: Of drivers who complete both BGC and vehicle addition,\\n{both_to_converted_pct:.1f}% go on to complete their first trip\",\n",
    "               ha=\"center\", fontsize=12, bbox={\"facecolor\":\"lightgreen\", \"alpha\":0.3, \"pad\":5})\n",
    "    \n",
    "    plt.tight_layout(rect=[0.05, 0.07, 1, 0.98])\n",
    "    plt.savefig('uber_driver_conversion_funnel.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def create_combined_dashboard():\n",
    "    \"\"\"Create a combined dashboard with all visualizations.\"\"\"\n",
    "    # Create figure with a complex grid layout\n",
    "    fig = plt.figure(figsize=(20, 16))\n",
    "    gs = gridspec.GridSpec(3, 3, figure=fig, height_ratios=[1, 1, 1.2])\n",
    "    \n",
    "    # 1. Missing Data Visualization (top left)\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    create_missing_data_mini(ax1)\n",
    "    \n",
    "    # 2. Conversion Funnel (top center and right)\n",
    "    ax2 = fig.add_subplot(gs[0, 1:])\n",
    "    create_funnel_mini(ax2)\n",
    "    \n",
    "    # 3. Conversion by BGC and Vehicle (middle left)\n",
    "    ax3 = fig.add_subplot(gs[1, 0])\n",
    "    create_bgc_vehicle_mini(ax3)\n",
    "    \n",
    "    # 4. Conversion by Channel (middle center)\n",
    "    ax4 = fig.add_subplot(gs[1, 1])\n",
    "    create_channel_mini(ax4)\n",
    "    \n",
    "    # 5. Funnel Completion (middle right)\n",
    "    ax5 = fig.add_subplot(gs[1, 2])\n",
    "    create_funnel_completion_mini(ax5)\n",
    "    \n",
    "    # 6. Feature Importance (bottom left and center)\n",
    "    ax6 = fig.add_subplot(gs[2, :2])\n",
    "    create_feature_importance_mini(ax6)\n",
    "    \n",
    "    # 7. Model Performance (bottom right)\n",
    "    ax7 = fig.add_subplot(gs[2, 2])\n",
    "    create_model_performance_mini(ax7)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('Uber Driver Conversion Analysis Dashboard', fontsize=20, fontweight='bold', y=0.98)\n",
    "    \n",
    "    # Add explanatory text at the bottom\n",
    "    plt.figtext(0.5, 0.01, \n",
    "               \"Key Insights:\\n\"\n",
    "               \"• Only 11.22% of driver signups complete their first trip\\n\"\n",
    "               \"• Background check (BGC) and vehicle addition are essential steps - no drivers convert without BGC\\n\"\n",
    "               \"• Referral channel produces the highest quality signups (19.89% conversion vs. 6-9% for other channels)\\n\"\n",
    "               \"• Drivers who complete both BGC and vehicle steps convert at 45.59%, showing the importance of funnel completion\\n\"\n",
    "               \"• The predictive model achieves 89.33% accuracy, helping identify which drivers are likely to convert\",\n",
    "               ha=\"center\", fontsize=12, bbox={\"facecolor\":\"#f0f0f0\", \"alpha\":0.9, \"pad\":5})\n",
    "    \n",
    "    plt.savefig('uber_driver_analysis_dashboard.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# Mini visualization functions for the dashboard\n",
    "def create_missing_data_mini(ax):\n",
    "    \"\"\"Create a mini visualization of missing data.\"\"\"\n",
    "    df = pd.DataFrame(missing_data)\n",
    "    df['missing_percentage'] = df['missing_count'] / df['total'] * 100\n",
    "    df = df.sort_values('missing_percentage', ascending=False)\n",
    "    \n",
    "    bars = ax.barh(df['column'], df['missing_percentage'], color=sns.color_palette(\"viridis\", len(df)))\n",
    "    \n",
    "    ax.set_xlabel('% Missing', fontsize=10)\n",
    "    ax.set_title('Missing Data', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlim(0, 100)\n",
    "    \n",
    "    # Remove ytick labels\n",
    "    ax.set_yticklabels(df['column'], fontsize=8)\n",
    "\n",
    "def create_funnel_mini(ax):\n",
    "    \"\"\"Create a mini conversion funnel visualization.\"\"\"\n",
    "    total_drivers = 54681\n",
    "    drivers_with_bgc = 32896\n",
    "    drivers_with_vehicle = 13134\n",
    "    drivers_with_both = 12879\n",
    "    converted_drivers = 6137\n",
    "    \n",
    "    # Calculate percentages\n",
    "    bgc_pct = drivers_with_bgc / total_drivers * 100\n",
    "    vehicle_pct = drivers_with_vehicle / total_drivers * 100\n",
    "    both_pct = drivers_with_both / total_drivers * 100\n",
    "    converted_pct = converted_drivers / total_drivers * 100\n",
    "    \n",
    "    # Define the stages\n",
    "    stages = ['Total Signups', 'BGC Completed', 'Vehicle Added', 'Both Steps Completed', 'First Trip Completed']\n",
    "    values = [total_drivers, drivers_with_bgc, drivers_with_vehicle, drivers_with_both, converted_drivers]\n",
    "    percentages = [100, bgc_pct, vehicle_pct, both_pct, converted_pct]\n",
    "    \n",
    "    # Create a gradient of colors\n",
    "    colors = plt.cm.viridis(np.linspace(0.8, 0.3, len(stages)))\n",
    "    \n",
    "    # Create bars\n",
    "    y_pos = np.arange(len(stages))\n",
    "    bars = ax.barh(y_pos, percentages, color=colors)\n",
    "    \n",
    "    # Add count and percentage inside the bar\n",
    "    for i, (bar, value, pct) in enumerate(zip(bars, values, percentages)):\n",
    "        ax.text(5, i, f\"{value:,} ({pct:.1f}%)\", va='center', fontsize=7, \n",
    "                color='white' if i > 0 else 'black')\n",
    "    \n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(stages, fontsize=9)\n",
    "    ax.set_xlim(0, 105)\n",
    "    ax.set_title('Driver Conversion Funnel', fontsize=12, fontweight='bold')\n",
    "    ax.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "\n",
    "def create_bgc_vehicle_mini(ax):\n",
    "    \"\"\"Create mini visualizations for BGC and vehicle conversion rates.\"\"\"\n",
    "    # BGC Completion\n",
    "    bgc_labels = list(conversion_data['bgc_completed'].keys())\n",
    "    bgc_values = list(conversion_data['bgc_completed'].values())\n",
    "    vehicle_labels = list(conversion_data['vehicle_added'].keys())\n",
    "    vehicle_values = list(conversion_data['vehicle_added'].values())\n",
    "    \n",
    "    # Combine data\n",
    "    labels = bgc_labels + vehicle_labels\n",
    "    values = bgc_values + vehicle_values\n",
    "    colors = ['#1976D2', '#64B5F6', '#388E3C', '#81C784']\n",
    "    \n",
    "    # Add group column\n",
    "    group = ['BGC'] * len(bgc_labels) + ['Vehicle'] * len(vehicle_labels)\n",
    "    \n",
    "    # Create grouped bar chart\n",
    "    x = np.arange(len(set(group)))\n",
    "    width = 0.35\n",
    "    \n",
    "    # BGC bars\n",
    "    ax.bar(x[0] - width/2, bgc_values[0], width, label=bgc_labels[0], color=colors[0])\n",
    "    ax.bar(x[0] + width/2, bgc_values[1], width, label=bgc_labels[1], color=colors[1])\n",
    "    \n",
    "    # Vehicle bars\n",
    "    ax.bar(x[1] - width/2, vehicle_values[0], width, label=vehicle_labels[0], color=colors[2])\n",
    "    ax.bar(x[1] + width/2, vehicle_values[1], width, label=vehicle_labels[1], color=colors[3])\n",
    "    \n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(['Background Check', 'Vehicle Addition'])\n",
    "    ax.set_ylim(0, 50)\n",
    "    ax.set_ylabel('Conversion Rate (%)')\n",
    "    ax.set_title('Conversion by Onboarding Steps', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, v in enumerate([bgc_values[0], bgc_values[1], vehicle_values[0], vehicle_values[1]]):\n",
    "        x_pos = (i % 2) * 1 + (0.5 if i % 2 else -0.5) * width\n",
    "        ax.text(x_pos, v + 1, f\"{v:.1f}%\", ha='center', va='bottom', fontsize=8)\n",
    "    \n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "def create_channel_mini(ax):\n",
    "    \"\"\"Create a mini visualization for conversion by signup channel.\"\"\"\n",
    "    channel_labels = list(conversion_data['signup_channel'].keys())\n",
    "    channel_values = list(conversion_data['signup_channel'].values())\n",
    "    \n",
    "    # Sort by conversion rate\n",
    "    sorted_indices = np.argsort(channel_values)[::-1]\n",
    "    channel_labels = [channel_labels[i] for i in sorted_indices]\n",
    "    channel_values = [channel_values[i] for i in sorted_indices]\n",
    "    \n",
    "    colors = ['#7B1FA2', '#9C27B0', '#BA68C8']\n",
    "    bars = ax.bar(channel_labels, channel_values, color=colors)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "                f\"{height:.1f}%\", ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    ax.set_ylim(0, 25)\n",
    "    ax.set_title('Conversion by Signup Channel', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Conversion Rate (%)')\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "def create_funnel_completion_mini(ax):\n",
    "    \"\"\"Create a mini visualization for conversion by funnel completion.\"\"\"\n",
    "    funnel_labels = list(conversion_data['funnel_completion'].keys())\n",
    "    funnel_values = list(conversion_data['funnel_completion'].values())\n",
    "    \n",
    "    # Sort by conversion rate\n",
    "    sorted_indices = np.argsort(funnel_values)[::-1]\n",
    "    funnel_labels = [funnel_labels[i] for i in sorted_indices]\n",
    "    funnel_values = [funnel_values[i] for i in sorted_indices]\n",
    "    \n",
    "    colors = ['#E65100', '#FB8C00', '#FFB74D', '#FFE0B2']\n",
    "    bars = ax.bar(funnel_labels, funnel_values, color=colors)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                f\"{height:.1f}%\", ha='center', va='bottom', fontsize=8)\n",
    "    \n",
    "    ax.set_ylim(0, 50)\n",
    "    ax.set_title('Conversion by Funnel Completion', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Conversion Rate (%)')\n",
    "    ax.set_xticklabels(funnel_labels, rotation=45, ha='right', fontsize=8)\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "def create_feature_importance_mini(ax):\n",
    "    \"\"\"Create a mini visualization of feature importance.\"\"\"\n",
    "    df = pd.DataFrame(feature_importance)\n",
    "    df = df.sort_values('Importance', ascending=True)\n",
    "    \n",
    "    colors = plt.cm.viridis(np.linspace(0.1, 0.9, len(df)))\n",
    "    bars = ax.barh(df['Feature'], df['Importance'], color=colors)\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, bar in enumerate(bars):\n",
    "        width = bar.get_width()\n",
    "        ax.text(width + 0.1, i, f\"{width:.2f}\", va='center', fontsize=8)\n",
    "    \n",
    "    ax.set_xlabel('Importance Score')\n",
    "    ax.set_title('Feature Importance in Prediction Model', fontsize=12, fontweight='bold')\n",
    "    ax.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "\n",
    "def create_model_performance_mini(ax):\n",
    "    \"\"\"Create a mini visualization of model performance metrics.\"\"\"\n",
    "    metrics = list(model_performance.keys())\n",
    "    values = list(model_performance.values())\n",
    "    \n",
    "    # Create bars with a color gradient\n",
    "    colors = plt.cm.viridis(np.linspace(0.2, 0.8, len(metrics)))\n",
    "    bars = ax.bar(metrics, values, color=colors)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                f\"{height:.2f}\", ha='center', va='bottom', fontsize=8)\n",
    "    \n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_title('Model Performance Metrics', fontsize=12, fontweight='bold')\n",
    "    ax.set_xticklabels(metrics, rotation=45, ha='right', fontsize=9)\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Create all visualizations\n",
    "if __name__ == \"__main__\":\n",
    "    create_missing_data_visualization()\n",
    "    create_conversion_rate_visualization()\n",
    "    create_feature_importance_visualization()\n",
    "    create_model_performance_visualization()\n",
    "    create_funnel_visualization()\n",
    "    create_combined_dashboard()\n",
    "    \n",
    "    print(\"All visualizations saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed funnel visualization saved as 'fixed_funnel_text_complete.png'\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set style for better visualizations\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = ['Arial', 'Helvetica', 'DejaVu Sans']\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "\n",
    "# Define the funnel data\n",
    "stages = [\n",
    "    'Total Signups',\n",
    "    'BGC Completed',\n",
    "    'Vehicle Added',\n",
    "    'Both Steps Completed',\n",
    "    'First Trip Completed'\n",
    "]\n",
    "\n",
    "values = [54681, 32896, 13134, 12879, 6137]\n",
    "percentages = [100.0, 60.2, 24.0, 23.6, 11.2]\n",
    "\n",
    "# Create specific colors for each stage\n",
    "bar_colors = ['#455a64', '#4caf50', '#26a69a', '#5c6bc0', '#9c27b0']\n",
    "\n",
    "# Create the figure\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "# Create horizontal bars - reversed to show in descending order\n",
    "y_pos = np.arange(len(stages))\n",
    "bars = ax.barh(y_pos[::-1], percentages, height=0.6, color=bar_colors, alpha=0.9, edgecolor='none')\n",
    "\n",
    "# Remove the frame\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "\n",
    "# Add a subtle grid\n",
    "ax.grid(True, axis='x', alpha=0.2, linestyle='--')\n",
    "\n",
    "# Set limits for better spacing\n",
    "ax.set_xlim(0, 105)\n",
    "ax.set_ylim(-0.5, len(stages) - 0.5)\n",
    "\n",
    "# Add value labels with both absolute numbers and percentages\n",
    "for i, (bar, value, percentage) in enumerate(zip(bars, values, percentages)):\n",
    "    # Format with commas for thousands\n",
    "    label_text = f\"{value:,} ({percentage:.1f}%)\"\n",
    "    \n",
    "    # Special handling for \"First Trip Completed\" to ensure full text is visible\n",
    "    if i == 4:  # First Trip Completed\n",
    "        x_pos = 5.5  # Position text inside bar but close to the left edge\n",
    "        # First clear any previous text at this position to avoid overlapping\n",
    "        for txt in ax.texts:\n",
    "            if txt.get_position()[1] == len(stages) - 1 - i:\n",
    "                txt.remove()\n",
    "        # Add new text\n",
    "        ax.text(x_pos, len(stages) - 1 - i, label_text, va='center', ha='left', \n",
    "                color='white', fontweight='bold', fontsize=12, zorder=10)\n",
    "    else:\n",
    "        # For other bars\n",
    "        x_pos = 5  # Standard inside position\n",
    "        ax.text(x_pos, len(stages) - 1 - i, label_text, va='center', ha='left', \n",
    "                color='white', fontweight='bold', fontsize=12)\n",
    "\n",
    "# Add stage labels on the left side\n",
    "for i, stage in enumerate(stages):\n",
    "    ax.text(-2.5, len(stages) - 1 - i, stage, va='center', ha='right', fontweight='bold', fontsize=12)\n",
    "\n",
    "# Create title and subtitle\n",
    "plt.suptitle('Driver Conversion Funnel', fontsize=20, fontweight='bold', y=0.98)\n",
    "ax.set_title('Percentage of drivers completing each stage of the onboarding process', \n",
    "             fontsize=13, pad=20, loc='left', color='#555555')\n",
    "\n",
    "# Set axis labels\n",
    "ax.set_xlabel(' ', fontsize=12, labelpad=10)\n",
    "ax.set_yticks([])  # Hide y-axis ticks since we have custom labels\n",
    "\n",
    "# Add a key insight text at the bottom\n",
    "both_to_trip_percentage = (6137 / 12879) * 100\n",
    "key_insight_text = f\"Key Insight: Of drivers who complete both BGC and vehicle addition, {both_to_trip_percentage:.1f}% go on to complete their first trip\"\n",
    "plt.figtext(0.5, 0.05, key_insight_text, ha='center', va='center', \n",
    "           color='#2c3e50', fontsize=13, fontweight='bold',\n",
    "           bbox=dict(facecolor='#f8f9fa', edgecolor='#3498db', boxstyle='round,pad=0.6', alpha=0.9))\n",
    "\n",
    "# Add dropoff percentages between stages\n",
    "for i in range(len(stages)-1):\n",
    "    dropoff = percentages[i] - percentages[i+1]\n",
    "    dropoff_text = f\"↓ {dropoff:.1f}%\"\n",
    "    \n",
    "    # Position between stages\n",
    "    x_pos = percentages[i+1] + (percentages[i] - percentages[i+1])/2\n",
    "    y_pos = len(stages) - 1 - i - 0.5\n",
    "    \n",
    "    # Only add if dropoff is significant\n",
    "    if dropoff > 3:\n",
    "        ax.text(x_pos, y_pos, dropoff_text, va='center', ha='center', \n",
    "               color='#e74c3c', fontsize=10, fontweight='bold',\n",
    "               bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='white', alpha=0.7, edgecolor='#e74c3c', linewidth=1))\n",
    "\n",
    "# Add a subtle background color to the plot\n",
    "fig.patch.set_facecolor('#000000')\n",
    "ax.set_facecolor('#f9f9f9')\n",
    "\n",
    "# Disable box around the plot completely (to remove any blue lines)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_visible(False)\n",
    "\n",
    "# Ensure xticks are visible\n",
    "ax.tick_params(axis='x', colors='black')\n",
    "\n",
    "# Disable the blue line issue by explicitly setting no line style for the plot\n",
    "for line in ax.get_lines():\n",
    "    line.set_visible(False)\n",
    "\n",
    "# Save the visualization with high quality\n",
    "plt.savefig('fixed_funnel_text_complete.png', dpi=300, bbox_inches='tight', facecolor='#f9f9f9')\n",
    "plt.close()\n",
    "\n",
    "print(\"Fixed funnel visualization saved as 'fixed_funnel_text_complete.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final fixed funnel visualization saved as 'final_fixed_driver_conversion_funnel.png'\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "# Set style for better visualizations\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = ['Arial', 'Helvetica', 'DejaVu Sans']\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "\n",
    "# Define the funnel data\n",
    "stages = [\n",
    "    'Total Signups',\n",
    "    'BGC Completed',\n",
    "    'Vehicle Added',\n",
    "    'Both Steps Completed',\n",
    "    'First Trip Completed'\n",
    "]\n",
    "\n",
    "values = [54681, 32896, 13134, 12879, 6137]\n",
    "percentages = [100.0, 60.2, 24.0, 23.6, 11.2]\n",
    "\n",
    "# Calculate percentage of drivers who complete first trip after completing both steps\n",
    "both_to_trip_percentage = (6137 / 12879) * 100\n",
    "\n",
    "# Create specific colors for each stage\n",
    "bar_colors = ['#455a64', '#4caf50', '#26a69a', '#5c6bc0', '#9c27b0']\n",
    "\n",
    "# Create the figure\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "# Create horizontal bars - reversed to show in descending order\n",
    "y_pos = np.arange(len(stages))\n",
    "bars = ax.barh(y_pos[::-1], percentages, height=0.6, color=bar_colors, alpha=0.9, edgecolor='white', linewidth=1)\n",
    "\n",
    "# Add a subtle grid\n",
    "ax.grid(True, axis='x', alpha=0.2, linestyle='--')\n",
    "\n",
    "# Remove the frame and ticks from the axes\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)  # Also hide bottom spine to remove potential issues\n",
    "ax.tick_params(left=False)\n",
    "\n",
    "# Set limits for better spacing\n",
    "ax.set_xlim(0, 105)  # A bit extra space for labels\n",
    "ax.set_ylim(-0.5, len(stages) - 0.5)\n",
    "\n",
    "# Add value labels with both absolute numbers and percentages - ALL INSIDE THE BARS\n",
    "for i, (bar, value, percentage) in enumerate(zip(bars, values, percentages)):\n",
    "    # Format with commas for thousands\n",
    "    label_text = f\"{value:,} ({percentage:.1f}%)\"\n",
    "    \n",
    "    # Position the text inside the bar for all bars\n",
    "    # For smaller bars, adjust position to make sure text is fully visible\n",
    "    if percentage < 15 and i == 4:  # First Trip Completed\n",
    "        # Center the text in the bar\n",
    "        x_pos = percentage / 2\n",
    "    else:\n",
    "        x_pos = 5  # Standard inside position\n",
    "    \n",
    "    ax.text(x_pos, len(stages) - 1 - i, label_text, va='center', ha='left', \n",
    "            color='white', fontweight='bold', fontsize=12)\n",
    "\n",
    "# Add stage labels on the left side\n",
    "for i, stage in enumerate(stages):\n",
    "    ax.text(-2.5, len(stages) - 1 - i, stage, va='center', ha='right', fontweight='bold', fontsize=12)\n",
    "\n",
    "# Create title and subtitle\n",
    "plt.suptitle('Driver Conversion Funnel', fontsize=20, fontweight='bold', y=0.98)\n",
    "ax.set_title('Percentage of drivers completing each stage of the onboarding process', \n",
    "             fontsize=13, pad=20, loc='left', color='#555555')\n",
    "\n",
    "# Set axis labels\n",
    "ax.set_xlabel('Percentage of Initial Signups', fontsize=12, labelpad=10)\n",
    "ax.set_yticks([])  # Hide y-axis ticks since we have custom labels\n",
    "\n",
    "# Add a key insight text at the bottom\n",
    "key_insight_text = f\"Key Insight: Of drivers who complete both BGC and vehicle addition, {both_to_trip_percentage:.1f}% go on to complete their first trip\"\n",
    "plt.figtext(0.5, 0.05, key_insight_text, ha='center', va='center', \n",
    "           color='#2c3e50', fontsize=13, fontweight='bold',\n",
    "           bbox=dict(facecolor='#f8f9fa', edgecolor='#3498db', boxstyle='round,pad=0.6', alpha=0.9))\n",
    "\n",
    "# Add dropoff percentages between stages\n",
    "for i in range(len(stages)-1):\n",
    "    dropoff = percentages[i] - percentages[i+1]\n",
    "    dropoff_text = f\"↓ {dropoff:.1f}%\"\n",
    "    \n",
    "    # Position between stages\n",
    "    x_pos = percentages[i+1] + (percentages[i] - percentages[i+1])/2\n",
    "    y_pos = len(stages) - 1 - i - 0.5\n",
    "    \n",
    "    # Only add if dropoff is significant\n",
    "    if dropoff > 3:\n",
    "        ax.text(x_pos, y_pos, dropoff_text, va='center', ha='center', \n",
    "               color='#e74c3c', fontsize=10, fontweight='bold',\n",
    "               bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='white', alpha=0.7, edgecolor='#e74c3c', linewidth=1))\n",
    "\n",
    "# IMPORTANT: Do not add any connecting lines - they cause the blue line problem\n",
    "\n",
    "# Add a subtle background color to the plot\n",
    "fig.patch.set_facecolor('#f9f9f9')\n",
    "ax.set_facecolor('#f9f9f9')\n",
    "\n",
    "# Save the visualization with high quality\n",
    "plt.savefig('final_fixed_driver_conversion_funnel.png', dpi=300, bbox_inches='tight', facecolor='#f9f9f9')\n",
    "plt.close()\n",
    "\n",
    "print(\"Final fixed funnel visualization saved as 'final_fixed_driver_conversion_funnel.png'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
